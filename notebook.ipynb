{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a4e992-6cca-40ef-b7fe-7134727ca699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workout documents: 1\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data\n",
    "\n",
    "workout_docs = read_repo_data('ilhamksyuriadi', 'workout-recommendation')\n",
    "# dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "# evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "\n",
    "print(f\"workout documents: {len(workout_docs)}\")\n",
    "# print(f\"FAQ documents: {len(dtc_faq)}\")\n",
    "# print(f\"Evidently documents: {len(evidently_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a99cf2-5ef6-4cbb-91d6-4d329b1f0587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "Sample document keys: dict_keys(['content', 'filename'])\n",
      "Sample content length: 12897\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "print(f\"Number of documents: {len(workout_docs)}\")\n",
    "print(f\"Sample document keys: {workout_docs[0].keys()}\")\n",
    "print(f\"Sample content length: {len(workout_docs[0]['content'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854e5e3d-6f2b-4e49-87e0-f01e73d7b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple sliding window chunks: 17\n"
     ]
    }
   ],
   "source": [
    "# 2.1 simple chunking\n",
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "workout_docs_chunks = []\n",
    "\n",
    "for doc in workout_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content, 1500, 750)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    workout_docs_chunks.extend(chunks)\n",
    "\n",
    "print(f\"Simple sliding window chunks: {len(workout_docs_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744d5d85-e984-487d-8766-fb35fcdb3f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph+sliding chunks: 67\n"
     ]
    }
   ],
   "source": [
    "# 2.2 paragraph chungking + sliding windows\n",
    "import re\n",
    "def paragraph_chunking_with_sliding_window(text, max_paragraph_length=500, sliding_window_size=1000, sliding_window_step=500):\n",
    "    \"\"\"\n",
    "    Hybrid approach: Split by paragraphs, then apply sliding window to long paragraphs\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The document content to chunk\n",
    "    - max_paragraph_length: If paragraph is shorter than this, keep as-is\n",
    "    - sliding_window_size: Size for sliding window (applied to long paragraphs)\n",
    "    - sliding_window_step: Step for sliding window (creates overlap)\n",
    "    \n",
    "    Returns: List of chunks with metadata\n",
    "    \"\"\"\n",
    "    # Step 1: Split into paragraphs\n",
    "    paragraphs = re.split(r\"\\n\\s*\\n\", text.strip())\n",
    "    \n",
    "    all_chunks = []\n",
    "    chunk_counter = 0\n",
    "    \n",
    "    for para_idx, paragraph in enumerate(paragraphs):\n",
    "        # Clean up the paragraph\n",
    "        paragraph = paragraph.strip()\n",
    "        if not paragraph:  # Skip empty paragraphs\n",
    "            continue\n",
    "\n",
    "        # Debug: Check if we're getting tiny paragraphs\n",
    "        if len(paragraph) < 50:  # Very short paragraph\n",
    "            # Option 1: Skip it (if it's just whitespace/formatting)\n",
    "            # Option 2: Combine with next paragraph\n",
    "            continue  # Let's skip for now\n",
    "        \n",
    "        # Step 2: Check paragraph length\n",
    "        if len(paragraph) <= max_paragraph_length:\n",
    "            # Short paragraph: keep as-is\n",
    "            chunk_info = {\n",
    "                'chunk_id': chunk_counter,\n",
    "                'paragraph_index': para_idx,\n",
    "                'chunk': paragraph,\n",
    "                'chunk_type': 'whole_paragraph',\n",
    "                'length': len(paragraph),\n",
    "                'sliding_window_info': None  # Not applicable\n",
    "            }\n",
    "            all_chunks.append(chunk_info)\n",
    "            chunk_counter += 1\n",
    "        else:\n",
    "            # Step 3: Long paragraph - apply sliding window\n",
    "            window_chunks = sliding_window(\n",
    "                paragraph, \n",
    "                sliding_window_size, \n",
    "                sliding_window_step\n",
    "            )\n",
    "            \n",
    "            # Step 4: Format each window chunk\n",
    "            for window_idx, window_chunk in enumerate(window_chunks):\n",
    "                chunk_info = {\n",
    "                    'chunk_id': chunk_counter,\n",
    "                    'paragraph_index': para_idx,\n",
    "                    'chunk': window_chunk['chunk'],\n",
    "                    'chunk_type': 'sliding_window_segment',\n",
    "                    'length': len(window_chunk['chunk']),\n",
    "                    'sliding_window_info': {\n",
    "                        'window_index': window_idx,\n",
    "                        'total_windows': len(window_chunks),\n",
    "                        'char_start': window_chunk['start'],\n",
    "                        'char_end': window_chunk['start'] + len(window_chunk['chunk']),\n",
    "                        'original_paragraph_length': len(paragraph)\n",
    "                    }\n",
    "                }\n",
    "                all_chunks.append(chunk_info)\n",
    "                chunk_counter += 1\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "def apply_paragraph_chunking_to_documents(documents):\n",
    "    \"\"\"Apply paragraph-based chunking to all documents - FIXED\"\"\"\n",
    "    all_chunks = []\n",
    "    \n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "        doc_copy = doc.copy()\n",
    "        doc_content = doc_copy.pop('content')\n",
    "        \n",
    "        # FIXED PARAMETERS:\n",
    "        chunks = paragraph_chunking_with_sliding_window(\n",
    "            doc_content,\n",
    "            max_paragraph_length=500,        # Paragraphs under 500 chars stay whole\n",
    "            sliding_window_size=1000,        # Reasonable chunk size\n",
    "            sliding_window_step=500          # 50% overlap\n",
    "        )\n",
    "        \n",
    "        # Add document metadata\n",
    "        for chunk in chunks:\n",
    "            chunk_with_metadata = doc_copy.copy()\n",
    "            chunk_with_metadata.update(chunk)\n",
    "            all_chunks.append(chunk_with_metadata)\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "workout_docs_chunks_2 = apply_paragraph_chunking_to_documents(workout_docs)\n",
    "print(f\"Paragraph+sliding chunks: {len(workout_docs_chunks_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966a1c64-a59e-4578-834c-127ac827482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section chunks (level 2): 14\n",
      "Section chunks (level 3): 28\n"
     ]
    }
   ],
   "source": [
    "# 2.3 section chunking\n",
    "def split_markdown_by_level_improved(text, level=2, include_content_before_first_header=True):\n",
    "    \"\"\"\n",
    "    Improved version that handles content before first header.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: Markdown text\n",
    "    - level: Header level to split on (1 for #, 2 for ##, etc.)\n",
    "    - include_content_before_first_header: Whether to include text before first header as a section\n",
    "    \n",
    "    Returns: List of (header, content) tuples\n",
    "    \"\"\"\n",
    "    # Create the regex pattern for the specified level\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "    \n",
    "    # Find all header positions\n",
    "    matches = list(pattern.finditer(text))\n",
    "    \n",
    "    if not matches:\n",
    "        # No headers found at this level\n",
    "        return [('No Header', text.strip())] if text.strip() else []\n",
    "    \n",
    "    sections = []\n",
    "    \n",
    "    # Handle content before first header\n",
    "    first_match = matches[0]\n",
    "    if include_content_before_first_header and first_match.start() > 0:\n",
    "        before_content = text[:first_match.start()].strip()\n",
    "        if before_content:\n",
    "            sections.append(('Introduction', before_content))\n",
    "    \n",
    "    # Process each section\n",
    "    for i, match in enumerate(matches):\n",
    "        header_marker = match.group(1)  # e.g., \"## \"\n",
    "        header_text = match.group(2)    # e.g., \"Installation\"\n",
    "        full_header = header_marker + header_text\n",
    "        \n",
    "        # Determine the content for this section\n",
    "        if i < len(matches) - 1:\n",
    "            # Content is from after this header to before next header\n",
    "            next_match = matches[i + 1]\n",
    "            content = text[match.end():next_match.start()].strip()\n",
    "        else:\n",
    "            # Last section: content is from after header to end\n",
    "            content = text[match.end():].strip()\n",
    "        \n",
    "        sections.append((full_header, content))\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def apply_section_chunking_to_documents(documents, level=2):\n",
    "    all_chunks = []\n",
    "    \n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "        doc_copy = doc.copy()\n",
    "        doc_content = doc_copy.pop('content')\n",
    "        \n",
    "        sections = split_markdown_by_level_improved(doc_content, level=level)\n",
    "        \n",
    "        for section_idx, (header, content) in enumerate(sections):\n",
    "            if not content:\n",
    "                continue\n",
    "                \n",
    "            chunk_info = {\n",
    "                'chunk_id': f\"doc_{doc_idx}_sec_{section_idx}\",\n",
    "                'header': header,\n",
    "                'chunk': content,\n",
    "                'chunk_type': f'section_level_{level}',\n",
    "                'section_index': section_idx,\n",
    "                'length': len(content),\n",
    "                'has_header': header != 'No Header' and header != 'Introduction'\n",
    "            }\n",
    "            \n",
    "            chunk_with_metadata = doc_copy.copy()\n",
    "            chunk_with_metadata.update(chunk_info)\n",
    "            all_chunks.append(chunk_with_metadata)\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "# Try multiple levels\n",
    "workout_docs_chunks_3_level2 = apply_section_chunking_to_documents(workout_docs, level=2)\n",
    "workout_docs_chunks_3_level3 = apply_section_chunking_to_documents(workout_docs, level=3)\n",
    "\n",
    "print(f\"Section chunks (level 2): {len(workout_docs_chunks_3_level2)}\")\n",
    "print(f\"Section chunks (level 3): {len(workout_docs_chunks_3_level3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7630bde-a2c2-4f33-9084-ff5d6095701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_chunking_method(chunks, method_name):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of a chunking method\n",
    "    \"\"\"\n",
    "    if not chunks:\n",
    "        return {}\n",
    "    \n",
    "    # Extract chunk contents\n",
    "    chunk_contents = []\n",
    "    for chunk in chunks:\n",
    "        content = chunk.get('chunk') or chunk.get('section') or ''\n",
    "        chunk_contents.append(content)\n",
    "    \n",
    "    # Basic statistics\n",
    "    sizes = [len(content) for content in chunk_contents]\n",
    "    char_counts = sizes\n",
    "    \n",
    "    # Token estimation (approx: 1 token ‚âà 4 chars for English)\n",
    "    token_counts = [len(content) // 4 for content in chunk_contents]\n",
    "    \n",
    "    # Distribution analysis\n",
    "    import statistics\n",
    "    \n",
    "    metrics = {\n",
    "        'method': method_name,\n",
    "        'total_chunks': len(chunks),\n",
    "        'total_characters': sum(char_counts),\n",
    "        'avg_chars_per_chunk': statistics.mean(char_counts),\n",
    "        'median_chars_per_chunk': statistics.median(char_counts),\n",
    "        'std_chars_per_chunk': statistics.stdev(char_counts) if len(char_counts) > 1 else 0,\n",
    "        'min_chars': min(char_counts),\n",
    "        'max_chars': max(char_counts),\n",
    "        'avg_tokens_per_chunk': statistics.mean(token_counts),\n",
    "        # Distribution percentiles\n",
    "        'p25_chars': sorted(char_counts)[int(len(char_counts) * 0.25)] if char_counts else 0,\n",
    "        'p75_chars': sorted(char_counts)[int(len(char_counts) * 0.75)] if char_counts else 0,\n",
    "    }\n",
    "    \n",
    "    # Size categories (useful for visualization)\n",
    "    small = len([c for c in char_counts if c < 500])\n",
    "    medium = len([c for c in char_counts if 500 <= c < 2000])\n",
    "    large = len([c for c in char_counts if c >= 2000])\n",
    "    \n",
    "    metrics['size_distribution'] = {\n",
    "        'small_<500': small,\n",
    "        'medium_500-2000': medium,\n",
    "        'large_>=2000': large,\n",
    "        'small_percent': (small / len(char_counts) * 100) if char_counts else 0\n",
    "    }\n",
    "    \n",
    "    # Context preservation score (estimated)\n",
    "    # Count how many chunks seem \"complete\"\n",
    "    complete_chunks = 0\n",
    "    for content in chunk_contents[:100]:  # Sample first 100 for speed\n",
    "        # Simple heuristics for \"completeness\"\n",
    "        if content.strip() and len(content) > 50:\n",
    "            # Check if ends with sentence-ending punctuation\n",
    "            # FIXED LINE: Removed the extra ')'\n",
    "            if content[-1] in '.!?' or '\\n\\n' in content[-20:]:\n",
    "                complete_chunks += 1\n",
    "    \n",
    "    metrics['estimated_completeness_score'] = (\n",
    "        complete_chunks / min(100, len(chunks)) * 100 \n",
    "        if chunks else 0\n",
    "    )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "sliding_analysis = analyze_chunking_method(workout_docs_chunks, 'sliding_window')\n",
    "paragraph_analysis = analyze_chunking_method(workout_docs_chunks_2, 'paragraph_sliding')\n",
    "section_analysis_2 = analyze_chunking_method(workout_docs_chunks_3_level2, 'section_level_2')\n",
    "section_analysis_3 = analyze_chunking_method(workout_docs_chunks_3_level3, 'section_level_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990e5bbb-cd7a-4fd4-8b2b-d7bfb0d65dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CHUNKING METHOD COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Metric                             sliding_window paragraph_slidingsection_level_2section_level_3\n",
      "--------------------------------------------------------------------------------\n",
      "total_chunks                                  17               67               14               28    \n",
      "avg_chars_per_chunk                         1465              171              901              436    \n",
      "min_chars                                    897               50              161               29    \n",
      "max_chars                                   1500              923             2864             1924    \n",
      "estimated_completeness_score                35.3%           11.9%          100.0%           14.3%  \n",
      "size_distribution.small_<500                   0               65                4               20    \n",
      "size_distribution.medium_500-2000             17                2                9                8    \n",
      "size_distribution.large_>=2000                 0                0                1                0    \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üîç KEY INSIGHTS (Look for these patterns):\n",
      "1. More chunks = better granularity for search\n",
      "2. Higher completeness score = better context preservation\n",
      "3. Balanced size distribution = good for most use cases\n",
      "4. Large max_chars might indicate poor boundary detection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sliding_window': {'method': 'sliding_window',\n",
       "  'total_chunks': 17,\n",
       "  'total_characters': 24897,\n",
       "  'avg_chars_per_chunk': 1464.5294117647059,\n",
       "  'median_chars_per_chunk': 1500,\n",
       "  'std_chars_per_chunk': 146.2489818969088,\n",
       "  'min_chars': 897,\n",
       "  'max_chars': 1500,\n",
       "  'avg_tokens_per_chunk': 366.11764705882354,\n",
       "  'p25_chars': 1500,\n",
       "  'p75_chars': 1500,\n",
       "  'size_distribution': {'small_<500': 0,\n",
       "   'medium_500-2000': 17,\n",
       "   'large_>=2000': 0,\n",
       "   'small_percent': 0.0},\n",
       "  'estimated_completeness_score': 35.294117647058826},\n",
       " 'paragraph_sliding': {'method': 'paragraph_sliding',\n",
       "  'total_chunks': 67,\n",
       "  'total_characters': 11456,\n",
       "  'avg_chars_per_chunk': 170.98507462686567,\n",
       "  'median_chars_per_chunk': 126,\n",
       "  'std_chars_per_chunk': 162.42634624861867,\n",
       "  'min_chars': 50,\n",
       "  'max_chars': 923,\n",
       "  'avg_tokens_per_chunk': 42.298507462686565,\n",
       "  'p25_chars': 75,\n",
       "  'p75_chars': 205,\n",
       "  'size_distribution': {'small_<500': 65,\n",
       "   'medium_500-2000': 2,\n",
       "   'large_>=2000': 0,\n",
       "   'small_percent': 97.01492537313433},\n",
       "  'estimated_completeness_score': 11.940298507462686},\n",
       " 'section_level_2': {'method': 'section_level_2',\n",
       "  'total_chunks': 14,\n",
       "  'total_characters': 12614,\n",
       "  'avg_chars_per_chunk': 901,\n",
       "  'median_chars_per_chunk': 747.5,\n",
       "  'std_chars_per_chunk': 741.2287096436564,\n",
       "  'min_chars': 161,\n",
       "  'max_chars': 2864,\n",
       "  'avg_tokens_per_chunk': 224.92857142857142,\n",
       "  'p25_chars': 392,\n",
       "  'p75_chars': 1179,\n",
       "  'size_distribution': {'small_<500': 4,\n",
       "   'medium_500-2000': 9,\n",
       "   'large_>=2000': 1,\n",
       "   'small_percent': 28.57142857142857},\n",
       "  'estimated_completeness_score': 100.0},\n",
       " 'section_level_3': {'method': 'section_level_3',\n",
       "  'total_chunks': 28,\n",
       "  'total_characters': 12216,\n",
       "  'avg_chars_per_chunk': 436.2857142857143,\n",
       "  'median_chars_per_chunk': 242.5,\n",
       "  'std_chars_per_chunk': 484.4483580736048,\n",
       "  'min_chars': 29,\n",
       "  'max_chars': 1924,\n",
       "  'avg_tokens_per_chunk': 108.67857142857143,\n",
       "  'p25_chars': 121,\n",
       "  'p75_chars': 615,\n",
       "  'size_distribution': {'small_<500': 20,\n",
       "   'medium_500-2000': 8,\n",
       "   'large_>=2000': 0,\n",
       "   'small_percent': 71.42857142857143},\n",
       "  'estimated_completeness_score': 14.285714285714285}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_analyses(all_analyses):\n",
    "    \"\"\"\n",
    "    Compare all analysis results in a readable format\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"CHUNKING METHOD COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Define the metrics to compare (in order of importance)\n",
    "    key_metrics = [\n",
    "        'total_chunks',\n",
    "        'avg_chars_per_chunk', \n",
    "        'min_chars',\n",
    "        'max_chars',\n",
    "        'estimated_completeness_score',\n",
    "        'size_distribution.small_<500',\n",
    "        'size_distribution.medium_500-2000',\n",
    "        'size_distribution.large_>=2000'\n",
    "    ]\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"\\n{'Metric':<35}\", end=\"\")\n",
    "    for method_name in all_analyses.keys():\n",
    "        print(f\"{method_name:<15}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print each metric\n",
    "    for metric in key_metrics:\n",
    "        print(f\"{metric:<35}\", end=\"\")\n",
    "        \n",
    "        for method_name, analysis in all_analyses.items():\n",
    "            # Handle nested metrics (size_distribution.small_<500)\n",
    "            if '.' in metric:\n",
    "                parts = metric.split('.')\n",
    "                value = analysis.get(parts[0], {})\n",
    "                if isinstance(value, dict):\n",
    "                    value = value.get(parts[1], 'N/A')\n",
    "            else:\n",
    "                value = analysis.get(metric, 'N/A')\n",
    "            \n",
    "            # Format the value\n",
    "            if isinstance(value, (int, float)):\n",
    "                if metric == 'estimated_completeness_score':\n",
    "                    print(f\"{value:>13.1f}%  \", end=\"\")\n",
    "                elif metric in ['avg_chars_per_chunk']:\n",
    "                    print(f\"{value:>13.0f}    \", end=\"\")\n",
    "                else:\n",
    "                    print(f\"{value:>13}    \", end=\"\")\n",
    "            else:\n",
    "                print(f\"{str(value):>13}    \", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Add interpretation\n",
    "    print(\"\\nüîç KEY INSIGHTS (Look for these patterns):\")\n",
    "    print(\"1. More chunks = better granularity for search\")\n",
    "    print(\"2. Higher completeness score = better context preservation\")\n",
    "    print(\"3. Balanced size distribution = good for most use cases\")\n",
    "    print(\"4. Large max_chars might indicate poor boundary detection\")\n",
    "    \n",
    "    return all_analyses\n",
    "\n",
    "# Run the comparison\n",
    "\n",
    "# Compare all\n",
    "all_analyses = {\n",
    "    'sliding_window': sliding_analysis,\n",
    "    'paragraph_sliding': paragraph_analysis,\n",
    "    'section_level_2': section_analysis_2,\n",
    "    'section_level_3': section_analysis_3\n",
    "}\n",
    "\n",
    "compare_analyses(all_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656d3923-e356-49f4-b4c0-f6c670e1e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VISUAL COMPARISON (ASCII Charts)\n",
      "======================================================================\n",
      "\n",
      "üìä TOTAL CHUNKS (More = finer granularity):\n",
      "sliding_window               17 chunks ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "paragraph_sliding            67 chunks ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_2              14 chunks ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_3              28 chunks ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üìè AVERAGE CHUNK SIZE (Chars):\n",
      "sliding_window             1465 chars ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "paragraph_sliding           171 chars ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_2             901 chars ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_3             436 chars ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "‚úÖ ESTIMATED COMPLETENESS SCORE (%):\n",
      "sliding_window             35.3% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "paragraph_sliding          11.9% ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_2           100.0% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_3            14.3% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üì¶ SIZE DISTRIBUTION:\n",
      "\n",
      "sliding_window:\n",
      "  Small (<500):   0.0%\n",
      "  Medium (500-2k):‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.0%\n",
      "  Large (‚â•2k):     0.0%\n",
      "\n",
      "paragraph_sliding:\n",
      "  Small (<500):  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 97.0%\n",
      "  Medium (500-2k):‚ñà 3.0%\n",
      "  Large (‚â•2k):     0.0%\n",
      "\n",
      "section_level_2:\n",
      "  Small (<500):  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 28.6%\n",
      "  Medium (500-2k):‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 64.3%\n",
      "  Large (‚â•2k):    ‚ñà‚ñà‚ñà 7.1%\n",
      "\n",
      "section_level_3:\n",
      "  Small (<500):  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 71.4%\n",
      "  Medium (500-2k):‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 28.6%\n",
      "  Large (‚â•2k):     0.0%\n"
     ]
    }
   ],
   "source": [
    "def create_visual_comparison(all_analyses):\n",
    "    \"\"\"\n",
    "    Create simple bar charts for key metrics\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"VISUAL COMPARISON (ASCII Charts)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Chart 1: Total Chunks\n",
    "    print(\"\\nüìä TOTAL CHUNKS (More = finer granularity):\")\n",
    "    max_chunks = max([a.get('total_chunks', 0) for a in all_analyses.values()])\n",
    "    \n",
    "    for method_name, analysis in all_analyses.items():\n",
    "        chunks = analysis.get('total_chunks', 0)\n",
    "        bar_length = int((chunks / max_chunks) * 50) if max_chunks > 0 else 0\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"{method_name:<25} {chunks:>5} chunks {bar}\")\n",
    "    \n",
    "    # Chart 2: Average Chunk Size\n",
    "    print(\"\\nüìè AVERAGE CHUNK SIZE (Chars):\")\n",
    "    max_avg = max([a.get('avg_chars_per_chunk', 0) for a in all_analyses.values()])\n",
    "    \n",
    "    for method_name, analysis in all_analyses.items():\n",
    "        avg_size = analysis.get('avg_chars_per_chunk', 0)\n",
    "        bar_length = int((avg_size / max_avg) * 50) if max_avg > 0 else 0\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"{method_name:<25} {avg_size:>5.0f} chars {bar}\")\n",
    "    \n",
    "    # Chart 3: Completeness Score\n",
    "    print(\"\\n‚úÖ ESTIMATED COMPLETENESS SCORE (%):\")\n",
    "    \n",
    "    for method_name, analysis in all_analyses.items():\n",
    "        score = analysis.get('estimated_completeness_score', 0)\n",
    "        bar_length = int(score / 2)  # 50 chars for 100%\n",
    "        bar = \"‚ñà\" * bar_length\n",
    "        print(f\"{method_name:<25} {score:>5.1f}% {bar}\")\n",
    "    \n",
    "    # Chart 4: Size Distribution\n",
    "    print(\"\\nüì¶ SIZE DISTRIBUTION:\")\n",
    "    for method_name, analysis in all_analyses.items():\n",
    "        dist = analysis.get('size_distribution', {})\n",
    "        small = dist.get('small_<500', 0)\n",
    "        medium = dist.get('medium_500-2000', 0)\n",
    "        large = dist.get('large_>=2000', 0)\n",
    "        total = small + medium + large\n",
    "        \n",
    "        if total > 0:\n",
    "            small_pct = (small / total) * 100\n",
    "            medium_pct = (medium / total) * 100\n",
    "            large_pct = (large / total) * 100\n",
    "            \n",
    "            print(f\"\\n{method_name}:\")\n",
    "            print(f\"  Small (<500):  {'‚ñà' * int(small_pct/2)} {small_pct:.1f}%\")\n",
    "            print(f\"  Medium (500-2k):{'‚ñà' * int(medium_pct/2)} {medium_pct:.1f}%\") \n",
    "            print(f\"  Large (‚â•2k):    {'‚ñà' * int(large_pct/2)} {large_pct:.1f}%\")\n",
    "\n",
    "create_visual_comparison(all_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c708d6-ba34-452f-a3ce-e7ba3a28cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç MANUAL CHUNK INSPECTION - ALL METHODS\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "MANUAL INSPECTION: Sliding Window (size=1500, step=750)\n",
      "============================================================\n",
      "\n",
      "üìÑ Example 1/17:\n",
      "   Source: Unknown\n",
      "   Length: 1500 characters\n",
      "   Type: unknown\n",
      "   Starts with capital letter: ‚ùå\n",
      "   Ends with punctuation: ‚ùå\n",
      "   ‚ö†Ô∏è  WARNING: Starts lowercase - likely cut mid-sentence\n",
      "   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"# üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user...\"\n",
      "\n",
      "   Ending (last 100 chars):\n",
      "   \"...get classes:\n",
      "- Cardio\n",
      "- Strength\n",
      "- Yoga\n",
      "- HIIT\n",
      "\n",
      "---\n",
      "\n",
      "## Dataset\n",
      "\n",
      "**Source**: [Kaggle - Gym Members E\"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "üìÑ Example 2/17:\n",
      "   Source: Unknown\n",
      "   Length: 1500 characters\n",
      "   Type: unknown\n",
      "   Starts with capital letter: ‚úÖ\n",
      "   Ends with punctuation: ‚ùå\n",
      "   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"The goal is to build a machine learning model that can predict which type of workout (Cardio, Strength, Yoga, or HIIT) would be most suitable for a pe...\"\n",
      "\n",
      "   Ending (last 100 chars):\n",
      "   \"...data with consistent formats\n",
      "\n",
      "---\n",
      "\n",
      "## Project Structure\n",
      "\n",
      "```\n",
      "workout-recommendation/\n",
      "‚îÇ\n",
      "‚îú‚îÄ‚îÄ data/\n",
      "‚îÇ  \"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "MANUAL INSPECTION: Paragraph + Sliding Window\n",
      "============================================================\n",
      "\n",
      "üìÑ Example 1/67:\n",
      "   Source: Unknown\n",
      "   Length: 150 characters\n",
      "   Type: whole_paragraph\n",
      "   Starts with capital letter: ‚úÖ\n",
      "   Ends with punctuation: ‚úÖ\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"A machine learning-based system that recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user physical attributes and fitness metrics....\"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "üìÑ Example 2/67:\n",
      "   Source: Unknown\n",
      "   Length: 387 characters\n",
      "   Type: whole_paragraph\n",
      "   Starts with capital letter: ‚ùå\n",
      "   Ends with punctuation: ‚ùå\n",
      "   ‚ö†Ô∏è  WARNING: Starts lowercase - likely cut mid-sentence\n",
      "   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"- [Problem Description](#problem-description)\n",
      "- [Dataset](#dataset)\n",
      "- [Project Structure](#project-structure)\n",
      "- [Installation](#installation)\n",
      "- [Runni...\"\n",
      "\n",
      "   Ending (last 100 chars):\n",
      "   \"...#deployment)\n",
      "- [Technologies Used](#technologies-used)\n",
      "- [Future Improvements](#future-improvements)\"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "MANUAL INSPECTION: Section Chunking (Level 2)\n",
      "============================================================\n",
      "\n",
      "üìÑ Example 1/14:\n",
      "   Source: Unknown\n",
      "   Section: Introduction\n",
      "   Length: 191 characters\n",
      "   Type: section_level_2\n",
      "   Starts with capital letter: ‚ùå\n",
      "   Ends with punctuation: ‚úÖ\n",
      "   ‚ö†Ô∏è  WARNING: Starts lowercase - likely cut mid-sentence\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"# üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user...\"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "üìÑ Example 2/14:\n",
      "   Source: Unknown\n",
      "   Section: ## Table of Contents\n",
      "   Length: 392 characters\n",
      "   Type: section_level_2\n",
      "   Starts with capital letter: ‚ùå\n",
      "   Ends with punctuation: ‚ùå\n",
      "   ‚ö†Ô∏è  WARNING: Starts lowercase - likely cut mid-sentence\n",
      "   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"- [Problem Description](#problem-description)\n",
      "- [Dataset](#dataset)\n",
      "- [Project Structure](#project-structure)\n",
      "- [Installation](#installation)\n",
      "- [Runni...\"\n",
      "\n",
      "   Ending (last 100 chars):\n",
      "   \"...oyment)\n",
      "- [Technologies Used](#technologies-used)\n",
      "- [Future Improvements](#future-improvements)\n",
      "\n",
      "---\"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "MANUAL INSPECTION: Section Chunking (Level 3)\n",
      "============================================================\n",
      "\n",
      "üìÑ Example 1/28:\n",
      "   Source: Unknown\n",
      "   Section: Introduction\n",
      "   Length: 631 characters\n",
      "   Type: section_level_3\n",
      "   Starts with capital letter: ‚ùå\n",
      "   Ends with punctuation: ‚ùå\n",
      "   ‚ö†Ô∏è  WARNING: Starts lowercase - likely cut mid-sentence\n",
      "   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"# üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user...\"\n",
      "\n",
      "   Ending (last 100 chars):\n",
      "   \"...Used](#technologies-used)\n",
      "- [Future Improvements](#future-improvements)\n",
      "\n",
      "---\n",
      "\n",
      "## Problem Description\"\n",
      "\n",
      "   --------------------------------------------------\n",
      "\n",
      "üìÑ Example 2/28:\n",
      "   Source: Unknown\n",
      "   Section: ### The Challenge\n",
      "   Length: 475 characters\n",
      "   Type: section_level_3\n",
      "   Starts with capital letter: ‚úÖ\n",
      "   Ends with punctuation: ‚ùå\n",
      "   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\n",
      "\n",
      "   Preview (first 150 chars):\n",
      "   \"Recommending appropriate workout types based on user physical characteristics and fitness levels. The goal is to build a machine learning model that c...\"\n",
      "\n",
      "   Ending (last 100 chars):\n",
      "   \"... behavior (frequency, duration, calories burned)\n",
      "- Experience level (Beginner, Intermediate, Expert)\"\n",
      "\n",
      "   --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_chunk_examples(chunks, method_name, num_examples=2):\n",
    "    \"\"\"Get example chunks for manual inspection\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MANUAL INSPECTION: {method_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"No chunks available\")\n",
    "        return\n",
    "    \n",
    "    for i in range(min(num_examples, len(chunks))):\n",
    "        chunk = chunks[i]\n",
    "        content = chunk.get('chunk', '')\n",
    "        \n",
    "        print(f\"\\nüìÑ Example {i+1}/{len(chunks)}:\")\n",
    "        print(f\"   Source: {chunk.get('title', 'Unknown')}\")\n",
    "        \n",
    "        if 'header' in chunk:\n",
    "            print(f\"   Section: {chunk.get('header', 'N/A')}\")\n",
    "        \n",
    "        print(f\"   Length: {len(content)} characters\")\n",
    "        print(f\"   Type: {chunk.get('chunk_type', 'unknown')}\")\n",
    "        \n",
    "        # Boundary analysis\n",
    "        if content:\n",
    "            starts_capital = content[0].isupper()\n",
    "            ends_punctuation = content[-1] in '.!?'\n",
    "            print(f\"   Starts with capital letter: {'‚úÖ' if starts_capital else '‚ùå'}\")\n",
    "            print(f\"   Ends with punctuation: {'‚úÖ' if ends_punctuation else '‚ùå'}\")\n",
    "            \n",
    "            # Check for mid-sentence cuts\n",
    "            if not starts_capital:\n",
    "                print(f\"   ‚ö†Ô∏è  WARNING: Starts lowercase - likely cut mid-sentence\")\n",
    "            if not ends_punctuation:\n",
    "                print(f\"   ‚ö†Ô∏è  WARNING: No ending punctuation - might be incomplete\")\n",
    "        \n",
    "        # Content preview (first and last 100 chars)\n",
    "        print(f\"\\n   Preview (first 150 chars):\")\n",
    "        print(f\"   \\\"{content[:150]}...\\\"\")\n",
    "        \n",
    "        if len(content) > 200:\n",
    "            print(f\"\\n   Ending (last 100 chars):\")\n",
    "            print(f\"   \\\"...{content[-100:]}\\\"\")\n",
    "        \n",
    "        print(f\"\\n   {'-'*50}\")\n",
    "\n",
    "# Run for ALL FOUR methods\n",
    "print(\"üîç MANUAL CHUNK INSPECTION - ALL METHODS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Sliding Window\n",
    "get_chunk_examples(workout_docs_chunks, \"Sliding Window (size=1500, step=750)\")\n",
    "\n",
    "# 2. Paragraph + Sliding Window  \n",
    "get_chunk_examples(workout_docs_chunks_2, \"Paragraph + Sliding Window\")\n",
    "\n",
    "# 3. Section Level 2\n",
    "get_chunk_examples(workout_docs_chunks_3_level2, \"Section Chunking (Level 2)\")\n",
    "\n",
    "# 4. Section Level 3\n",
    "get_chunk_examples(workout_docs_chunks_3_level3, \"Section Chunking (Level 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03249b9a-6726-4d08-8e92-7ddebeb893d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE QUALITY ASSESSMENT - ALL METHODS\n",
      "======================================================================\n",
      "\n",
      "üî¨ QUALITY ASSESSMENT: Sliding Window\n",
      "--------------------------------------------------\n",
      "Assessing 5 sample chunks...\n",
      "\n",
      "Sample 1 (1500 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: # üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout typ...\n",
      "\n",
      "Sample 2 (1500 chars):\n",
      "  Complete: ‚ö†Ô∏è\n",
      "  Readable: ‚úÖ\n",
      "  Preview: gitignore                               # Git ignore file\n",
      "‚îî‚îÄ‚îÄ README.md                             ...\n",
      "\n",
      "Sample 3 (1500 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: th identical physical stats (same age, BMI, fitness level) can have completely different workout pre...\n",
      "\n",
      "Sample 4 (1500 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: criptions:**\n",
      "\n",
      "| Field | Type | Values | Description |\n",
      "|-------|------|--------|-------------|\n",
      "| age ...\n",
      "\n",
      "Sample 5 (897 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: entication\n",
      "   - Implement rate limiting\n",
      "   - Add batch prediction endpoint\n",
      "   - Create user profiles...\n",
      "\n",
      "üìà FINAL SCORES (0-1 scale):\n",
      "  Completeness   : 0.10 ‚ñà‚ñà\n",
      "  Readability    : 1.00 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Boundaries     : 0.10 ‚ñà‚ñà\n",
      "  Relevance      : 0.60 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "  Overall score: 0.45/1.0\n",
      "\n",
      "üî¨ QUALITY ASSESSMENT: Paragraph+Window\n",
      "--------------------------------------------------\n",
      "Assessing 5 sample chunks...\n",
      "\n",
      "Sample 1 (150 chars):\n",
      "  Complete: ‚úÖ\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: A machine learning-based system that recommends workout types (Cardio, Strength, Yoga, or HIIT) base...\n",
      "\n",
      "Sample 2 (127 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚ùå\n",
      "  Preview: ```bash\n",
      "# Clone the repository\n",
      "git clone https://github.com/ilhamksyuriadi/workout-recommendation.gi...\n",
      "\n",
      "Sample 3 (223 chars):\n",
      "  Complete: ‚ö†Ô∏è\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: Analysis shows that physical attributes have minimal variation across workout types:\n",
      "- Average BMI: ...\n",
      "\n",
      "Sample 4 (57 chars):\n",
      "  Complete: ‚ö†Ô∏è\n",
      "  Readable: ‚ùå\n",
      "  Preview: The application is deployed on Railway and accessible at:...\n",
      "\n",
      "Sample 5 (221 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: - Dataset from [Kaggle - Gym Members Exercise Dataset](https://www.kaggle.com/datasets/valakhorasani...\n",
      "\n",
      "üìà FINAL SCORES (0-1 scale):\n",
      "  Completeness   : 0.40 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Readability    : 0.30 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Boundaries     : 0.60 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Relevance      : 0.70 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "  Overall score: 0.50/1.0\n",
      "\n",
      "üî¨ QUALITY ASSESSMENT: Section Level 2\n",
      "--------------------------------------------------\n",
      "Assessing 5 sample chunks...\n",
      "\n",
      "Sample 1 (191 chars):\n",
      "  Complete: ‚ö†Ô∏è\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: # üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout typ...\n",
      "\n",
      "Sample 2 (718 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: **Source**: [Kaggle - Gym Members Exercise Dataset](https://www.kaggle.com/datasets/valakhorasani/gy...\n",
      "\n",
      "Sample 3 (2864 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: ### Models Compared\n",
      "\n",
      "| Model | Training Accuracy | Validation Accuracy | Test Accuracy |\n",
      "|-------|--...\n",
      "\n",
      "Sample 4 (544 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: ### Machine Learning\n",
      "- **scikit-learn** (1.3.0) - ML algorithms and preprocessing\n",
      "- **XGBoost** (2.0...\n",
      "\n",
      "Sample 5 (226 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: - Dataset from [Kaggle - Gym Members Exercise Dataset](https://www.kaggle.com/datasets/valakhorasani...\n",
      "\n",
      "üìà FINAL SCORES (0-1 scale):\n",
      "  Completeness   : 0.10 ‚ñà‚ñà\n",
      "  Readability    : 0.80 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Boundaries     : 0.10 ‚ñà‚ñà\n",
      "  Relevance      : 0.60 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "  Overall score: 0.40/1.0\n",
      "\n",
      "üî¨ QUALITY ASSESSMENT: Section Level 3\n",
      "--------------------------------------------------\n",
      "Assessing 5 sample chunks...\n",
      "\n",
      "Sample 1 (631 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: # üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout typ...\n",
      "\n",
      "Sample 2 (342 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: ```bash\n",
      "# Clone the repository\n",
      "git clone https://github.com/ilhamksyuriadi/workout-recommendation.gi...\n",
      "\n",
      "Sample 3 (1924 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: #### Why Is Accuracy Low?\n",
      "\n",
      "The model achieved modest accuracy (~30% validation, ~21% test) for sever...\n",
      "\n",
      "Sample 4 (193 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚ö†Ô∏è\n",
      "  Preview: - **scikit-learn** (1.3.0) - ML algorithms and preprocessing\n",
      "- **XGBoost** (2.0.0) - Gradient boosti...\n",
      "\n",
      "Sample 5 (934 chars):\n",
      "  Complete: ‚ùå\n",
      "  Readable: ‚úÖ\n",
      "  Preview: 1. **API Enhancements**\n",
      "   - Add authentication\n",
      "   - Implement rate limiting\n",
      "   - Add batch predicti...\n",
      "\n",
      "üìà FINAL SCORES (0-1 scale):\n",
      "  Completeness   : 0.00 \n",
      "  Readability    : 0.80 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Boundaries     : 0.00 \n",
      "  Relevance      : 0.50 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "  Overall score: 0.33/1.0\n"
     ]
    }
   ],
   "source": [
    "def assess_chunk_quality(chunks, method_name):\n",
    "    \"\"\"\n",
    "    Comprehensive quality assessment with scoring\n",
    "    \"\"\"\n",
    "    print(f\"\\nüî¨ QUALITY ASSESSMENT: {method_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"No chunks to assess\")\n",
    "        return\n",
    "    \n",
    "    # Sample 5 chunks for assessment\n",
    "    sample_size = min(5, len(chunks))\n",
    "    sample_indices = [0, len(chunks)//4, len(chunks)//2, len(chunks)*3//4, -1]\n",
    "    sample_indices = sample_indices[:sample_size]\n",
    "    \n",
    "    scores = {\n",
    "        'completeness': 0,      # Complete sentences/thoughts\n",
    "        'readability': 0,       # Can be understood alone\n",
    "        'boundaries': 0,        # Natural start/end\n",
    "        'relevance': 0          # Contains coherent topic\n",
    "    }\n",
    "    \n",
    "    print(f\"Assessing {sample_size} sample chunks...\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        chunk = chunks[idx]\n",
    "        content = chunk.get('chunk', '')\n",
    "        \n",
    "        print(f\"\\nSample {i+1} ({len(content)} chars):\")\n",
    "        \n",
    "        # Score completeness\n",
    "        starts_well = content and content[0].isupper()\n",
    "        ends_well = content and content[-1] in '.!?'\n",
    "        completeness = 1 if starts_well and ends_well else 0.5 if starts_well or ends_well else 0\n",
    "        scores['completeness'] += completeness\n",
    "        \n",
    "        # Score readability (simple heuristic)\n",
    "        word_count = len(content.split())\n",
    "        readability = 1 if word_count > 50 and '.' in content else 0.5 if word_count > 20 else 0\n",
    "        scores['readability'] += readability\n",
    "        \n",
    "        # Score boundaries\n",
    "        boundaries = 1 if starts_well else 0.5 if ends_well else 0\n",
    "        scores['boundaries'] += boundaries\n",
    "        \n",
    "        # Check for topic coherence (simple version)\n",
    "        unique_words = len(set(content.lower().split()[:20]))\n",
    "        relevance = 1 if unique_words < 15 else 0.5  # Fewer unique words = more focused\n",
    "        scores['relevance'] += relevance\n",
    "        \n",
    "        print(f\"  Complete: {'‚úÖ' if completeness == 1 else '‚ö†Ô∏è' if completeness == 0.5 else '‚ùå'}\")\n",
    "        print(f\"  Readable: {'‚úÖ' if readability == 1 else '‚ö†Ô∏è' if readability == 0.5 else '‚ùå'}\")\n",
    "        print(f\"  Preview: {content[:100]}...\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    for key in scores:\n",
    "        scores[key] = scores[key] / sample_size\n",
    "    \n",
    "    print(f\"\\nüìà FINAL SCORES (0-1 scale):\")\n",
    "    for key, score in scores.items():\n",
    "        bar = \"‚ñà\" * int(score * 20)\n",
    "        print(f\"  {key.capitalize():<15}: {score:.2f} {bar}\")\n",
    "    \n",
    "    overall = sum(scores.values()) / len(scores)\n",
    "    print(f\"\\n  Overall score: {overall:.2f}/1.0\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Assess all four methods\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE QUALITY ASSESSMENT - ALL METHODS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quality_scores = {}\n",
    "quality_scores['sliding'] = assess_chunk_quality(workout_docs_chunks, \"Sliding Window\")\n",
    "quality_scores['paragraph'] = assess_chunk_quality(workout_docs_chunks_2, \"Paragraph+Window\")\n",
    "quality_scores['section_l2'] = assess_chunk_quality(workout_docs_chunks_3_level2, \"Section Level 2\")\n",
    "quality_scores['section_l3'] = assess_chunk_quality(workout_docs_chunks_3_level3, \"Section Level 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52daa764-dc73-4515-a5b2-1859e3d25493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ COMPREHENSIVE ANALYSIS - ALL METRICS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE CHUNKING ANALYSIS DASHBOARD\n",
      "====================================================================================================\n",
      "\n",
      "üìà QUANTITATIVE METRICS TABLE:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "           Method  Total Chunks Avg Chars  Min Chars  Max Chars Auto Complete % Manual Overall Size Dist (S/M/L) Small % Comp Score Read Score Bound Score Rel Score\n",
      "   sliding_window            17      1465        897       1500           35.3%           0.00            0/17/0    0.0%       0.10       1.00        0.10      0.60\n",
      "paragraph_sliding            67       171         50        923           11.9%           0.00            65/2/0   97.0%       0.40       0.30        0.60      0.70\n",
      "  section_level_2            14       901        161       2864          100.0%           0.00             4/9/1   28.6%       0.10       0.80        0.10      0.60\n",
      "  section_level_3            28       436         29       1924           14.3%           0.00            20/8/0   71.4%       0.00       0.80        0.00      0.50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "VISUAL SCOREBOARD (Higher is Better)\n",
      "====================================================================================================\n",
      "\n",
      "Method              Total Chunks   Avg Size       Auto Complete  Manual Overall Readability    Boundaries     \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "sliding_window          17 N/A       1465 N/A      35.3% ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   N/A N/A       1.00 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  0.10 ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
      "paragraph_sliding       67 N/A        171 N/A      11.9% ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   N/A N/A       0.30 ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  0.60 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "section_level_2         14 N/A        901 N/A     100.0% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   N/A N/A       0.80 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë  0.10 ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
      "section_level_3         28 N/A        436 N/A      14.3% ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   N/A N/A       0.80 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë   N/A N/A     \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "PERFORMANCE RADAR (1-5 Scale)\n",
      "====================================================================================================\n",
      "\n",
      "Completeness   sliding_window            1.1 ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ  paragraph_sliding         1.3 ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ  section_level_2           2.8 ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ  section_level_3           0.4 ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ  \n",
      "\n",
      "Readability    sliding_window            5.0 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ  paragraph_sliding         1.5 ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ  section_level_2           4.0 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ  section_level_3           4.0 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ  \n",
      "\n",
      "Size Balance   sliding_window            2.7 ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ  paragraph_sliding         0.9 ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ  section_level_2           4.5 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ  section_level_3           2.2 ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ  \n",
      "\n",
      "Usefulness     sliding_window            3.0 ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ  paragraph_sliding         3.5 ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ  section_level_2           3.0 ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ  section_level_3           2.5 ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ  \n",
      "\n",
      "Boundary Qualitysliding_window            0.5 ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ  paragraph_sliding         3.0 ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ  section_level_2           0.5 ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ  section_level_3           0.0 ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "OVERALL SCORES (Average of 5 criteria):\n",
      "sliding_window           : 2.46/5.0 \n",
      "paragraph_sliding        : 2.03/5.0 \n",
      "section_level_2          : 2.95/5.0 üèÜ\n",
      "section_level_3          : 1.81/5.0 \n",
      "\n",
      "====================================================================================================\n",
      "SAMPLE CHUNKS COMPARISON (First 2 chunks)\n",
      "====================================================================================================\n",
      "\n",
      "================================================== SAMPLE #1 ==================================================\n",
      "\n",
      "üìÑ SLIDING_WINDOW:\n",
      "   Size: 1500  chars  |  Source: Unknown                       \n",
      "   Preview: # üèãÔ∏è Workout Type Recommendation System  A machine learning-based system that\n",
      "                recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user\n",
      "                physical attributes and fitness metrics.  ## Tabl...\n",
      "   Quality: ‚ùå Start | ‚ùå End\n",
      "\n",
      "üìÑ PARAGRAPH_SLIDING:\n",
      "   Size: 150   chars  |  Source: Unknown                       \n",
      "   Preview: A machine learning-based system that recommends workout types (Cardio, Strength,\n",
      "                Yoga, or HIIT) based on user physical attributes and fitness metrics.\n",
      "   Quality: ‚úÖ Start | ‚úÖ End\n",
      "\n",
      "üìÑ SECTION_LEVEL_2:\n",
      "   Size: 191   chars  |  Source: Unknown                       \n",
      "   Header: Introduction\n",
      "   Preview: # üèãÔ∏è Workout Type Recommendation System  A machine learning-based system that\n",
      "                recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user\n",
      "                physical attributes and fitness metrics.\n",
      "   Quality: ‚ùå Start | ‚úÖ End\n",
      "\n",
      "üìÑ SECTION_LEVEL_3:\n",
      "   Size: 631   chars  |  Source: Unknown                       \n",
      "   Header: Introduction\n",
      "   Preview: # üèãÔ∏è Workout Type Recommendation System  A machine learning-based system that\n",
      "                recommends workout types (Cardio, Strength, Yoga, or HIIT) based on user\n",
      "                physical attributes and fitness metrics.  ## Tabl...\n",
      "   Quality: ‚ùå Start | ‚ùå End\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "================================================== SAMPLE #2 ==================================================\n",
      "\n",
      "üìÑ SLIDING_WINDOW:\n",
      "   Size: 1500  chars  |  Source: Unknown                       \n",
      "   Preview: The goal is to build a machine learning model that can predict which type of\n",
      "                workout (Cardio, Strength, Yoga, or HIIT) would be most suitable for a person\n",
      "                based on their:  - Physical attributes (age, ...\n",
      "   Quality: ‚úÖ Start | ‚ùå End\n",
      "\n",
      "üìÑ PARAGRAPH_SLIDING:\n",
      "   Size: 387   chars  |  Source: Unknown                       \n",
      "   Preview: - [Problem Description](#problem-description) - [Dataset](#dataset) - [Project\n",
      "                Structure](#project-structure) - [Installation](#installation) - [Running the\n",
      "                Project](#running-the-project) - [Model Per...\n",
      "   Quality: ‚ùå Start | ‚ùå End\n",
      "\n",
      "üìÑ SECTION_LEVEL_2:\n",
      "   Size: 392   chars  |  Source: Unknown                       \n",
      "   Header: ## Table of Contents\n",
      "   Preview: - [Problem Description](#problem-description) - [Dataset](#dataset) - [Project\n",
      "                Structure](#project-structure) - [Installation](#installation) - [Running the\n",
      "                Project](#running-the-project) - [Model Per...\n",
      "   Quality: ‚ùå Start | ‚ùå End\n",
      "\n",
      "üìÑ SECTION_LEVEL_3:\n",
      "   Size: 475   chars  |  Source: Unknown                       \n",
      "   Header: ### The Challenge\n",
      "   Preview: Recommending appropriate workout types based on user physical characteristics\n",
      "                and fitness levels. The goal is to build a machine learning model that can\n",
      "                predict which type of workout (Cardio, Strength...\n",
      "   Quality: ‚úÖ Start | ‚ùå End\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "üéØ EXECUTIVE SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "üèÜ RANKING (Weighted Score):\n",
      "ü•á section_level_2     : 52.3/100\n",
      "ü•à sliding_window      : 40.6/100\n",
      "ü•â section_level_3     : 18.0/100\n",
      "4. paragraph_sliding   : 7.2/100\n",
      "\n",
      "üìã RECOMMENDATION:\n",
      "1. Use 'section_level_2' for best overall performance\n",
      "2. Consider 'sliding_window' as alternative\n",
      "3. Avoid 'paragraph_sliding' (lowest score)\n",
      "\n",
      "====================================================================================================\n",
      "ANALYSIS COMPLETE - All metrics displayed above\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "\n",
    "def create_comprehensive_comparison(all_chunk_sets, all_analyses, quality_scores):\n",
    "    \"\"\"\n",
    "    Create a complete dashboard showing ALL metrics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"COMPREHENSIVE CHUNKING ANALYSIS DASHBOARD\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Prepare data\n",
    "    methods = list(all_analyses.keys())\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = []\n",
    "    \n",
    "    for method in methods:\n",
    "        analysis = all_analyses.get(method, {})\n",
    "        quality = quality_scores.get(method.replace('sliding_window', 'sliding')\n",
    "                                     .replace('paragraph_sliding', 'paragraph')\n",
    "                                     .replace('section_level_2', 'section_l2')\n",
    "                                     .replace('section_level_3', 'section_l3'), {})\n",
    "        \n",
    "        # Extract metrics\n",
    "        row = {\n",
    "            'Method': method,\n",
    "            'Total Chunks': analysis.get('total_chunks', 0),\n",
    "            'Avg Chars': f\"{analysis.get('avg_chars_per_chunk', 0):.0f}\",\n",
    "            'Min Chars': analysis.get('min_chars', 0),\n",
    "            'Max Chars': analysis.get('max_chars', 0),\n",
    "            'Auto Complete %': f\"{analysis.get('estimated_completeness_score', 0):.1f}%\",\n",
    "            'Manual Overall': f\"{quality.get('overall', 0):.2f}\" if quality else \"N/A\",\n",
    "            'Size Dist (S/M/L)': f\"{analysis.get('size_distribution', {}).get('small_<500', 0)}/{analysis.get('size_distribution', {}).get('medium_500-2000', 0)}/{analysis.get('size_distribution', {}).get('large_>=2000', 0)}\",\n",
    "            'Small %': f\"{analysis.get('size_distribution', {}).get('small_percent', 0):.1f}%\",\n",
    "        }\n",
    "        \n",
    "        # Add quality sub-scores if available\n",
    "        if quality:\n",
    "            row.update({\n",
    "                'Comp Score': f\"{quality.get('completeness', 0):.2f}\",\n",
    "                'Read Score': f\"{quality.get('readability', 0):.2f}\",\n",
    "                'Bound Score': f\"{quality.get('boundaries', 0):.2f}\",\n",
    "                'Rel Score': f\"{quality.get('relevance', 0):.2f}\",\n",
    "            })\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Display as table\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 120)\n",
    "    \n",
    "    print(\"\\nüìà QUANTITATIVE METRICS TABLE:\")\n",
    "    print(\"-\" * 120)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_visual_scoreboard(all_analyses, quality_scores):\n",
    "    \"\"\"\n",
    "    Create a visual scoreboard with color coding\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"VISUAL SCOREBOARD (Higher is Better)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    methods = list(all_analyses.keys())\n",
    "    \n",
    "    # Define metrics to display\n",
    "    metrics = [\n",
    "        ('Total Chunks', 'total_chunks', 'numeric', False),  # Not always \"higher is better\"\n",
    "        ('Avg Size', 'avg_chars_per_chunk', 'numeric', True),  # Optimal range is better\n",
    "        ('Auto Complete', 'estimated_completeness_score', 'percent', True),\n",
    "        ('Manual Overall', 'overall', 'score', True),\n",
    "        ('Readability', 'readability', 'score', True),\n",
    "        ('Boundaries', 'boundaries', 'score', True),\n",
    "    ]\n",
    "    \n",
    "    # Get max values for scaling\n",
    "    max_values = {}\n",
    "    for metric_name, metric_key, metric_type, higher_is_better in metrics:\n",
    "        values = []\n",
    "        for method in methods:\n",
    "            if metric_type == 'score':\n",
    "                # Get from quality_scores\n",
    "                method_key = method.replace('sliding_window', 'sliding')\\\n",
    "                                 .replace('paragraph_sliding', 'paragraph')\\\n",
    "                                 .replace('section_level_2', 'section_l2')\\\n",
    "                                 .replace('section_level_3', 'section_l3')\n",
    "                val = quality_scores.get(method_key, {}).get(metric_key, 0)\n",
    "            else:\n",
    "                # Get from all_analyses\n",
    "                val = all_analyses.get(method, {}).get(metric_key, 0)\n",
    "            if val:\n",
    "                values.append(float(str(val).replace('%', '')))\n",
    "        max_values[metric_key] = max(values) if values else 1\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"\\n{'Method':<20}\", end=\"\")\n",
    "    for metric_name, _, _, _ in metrics:\n",
    "        print(f\"{metric_name:<15}\", end=\"\")\n",
    "    print(\"\\n\" + \"-\" * (20 + 15 * len(metrics)))\n",
    "    \n",
    "    # Print each method\n",
    "    for method in methods:\n",
    "        print(f\"{method:<20}\", end=\"\")\n",
    "        \n",
    "        for metric_name, metric_key, metric_type, higher_is_better in metrics:\n",
    "            if metric_type == 'score':\n",
    "                method_key = method.replace('sliding_window', 'sliding')\\\n",
    "                                 .replace('paragraph_sliding', 'paragraph')\\\n",
    "                                 .replace('section_level_2', 'section_l2')\\\n",
    "                                 .replace('section_level_3', 'section_l3')\n",
    "                val = quality_scores.get(method_key, {}).get(metric_key, 0)\n",
    "                display_val = f\"{val:.2f}\" if val else \"N/A\"\n",
    "            else:\n",
    "                val = all_analyses.get(method, {}).get(metric_key, 0)\n",
    "                if metric_type == 'percent':\n",
    "                    display_val = f\"{val:.1f}%\" if val else \"N/A\"\n",
    "                else:\n",
    "                    display_val = f\"{val:.0f}\" if val else \"N/A\"\n",
    "            \n",
    "            # Add visual indicator\n",
    "            if val and metric_type in ['percent', 'score']:\n",
    "                normalized = float(str(val).replace('%', '')) / max_values[metric_key]\n",
    "                bars = int(normalized * 10)\n",
    "                visual = \"‚ñà\" * bars + \"‚ñë\" * (10 - bars)\n",
    "                print(f\"{display_val:>6} {visual:<8}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"{display_val:>6} {'N/A':<8}\", end=\"\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"-\" * (20 + 15 * len(metrics)))\n",
    "\n",
    "def create_radar_chart_data(all_analyses, quality_scores):\n",
    "    \"\"\"\n",
    "    Prepare data for a \"text-based radar chart\"\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"PERFORMANCE RADAR (1-5 Scale)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    methods = list(all_analyses.keys())\n",
    "    criteria = ['Completeness', 'Readability', 'Size Balance', 'Usefulness', 'Boundary Quality']\n",
    "    \n",
    "    # Score each method on each criterion (1-5)\n",
    "    scores = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        analysis = all_analyses.get(method, {})\n",
    "        method_key = method.replace('sliding_window', 'sliding')\\\n",
    "                         .replace('paragraph_sliding', 'paragraph')\\\n",
    "                         .replace('section_level_2', 'section_l2')\\\n",
    "                         .replace('section_level_3', 'section_l3')\n",
    "        quality = quality_scores.get(method_key, {})\n",
    "        \n",
    "        method_scores = []\n",
    "        \n",
    "        # 1. Completeness (auto + manual combined)\n",
    "        auto_comp = analysis.get('estimated_completeness_score', 0) / 100\n",
    "        manual_comp = quality.get('completeness', 0)\n",
    "        completeness = (auto_comp + manual_comp) / 2 * 5\n",
    "        method_scores.append(min(5, completeness))\n",
    "        \n",
    "        # 2. Readability\n",
    "        readability = quality.get('readability', 0) * 5\n",
    "        method_scores.append(min(5, readability))\n",
    "        \n",
    "        # 3. Size Balance (ideal: not too small, not too large)\n",
    "        avg_size = analysis.get('avg_chars_per_chunk', 0)\n",
    "        # Score: 5 if ~1000 chars, lower if far from ideal\n",
    "        size_score = 5 * (1 - min(abs(avg_size - 1000) / 1000, 1))\n",
    "        method_scores.append(min(5, size_score))\n",
    "        \n",
    "        # 4. Usefulness (estimated from relevance)\n",
    "        usefulness = quality.get('relevance', 0) * 5\n",
    "        method_scores.append(min(5, usefulness))\n",
    "        \n",
    "        # 5. Boundary Quality\n",
    "        boundaries = quality.get('boundaries', 0) * 5\n",
    "        method_scores.append(min(5, boundaries))\n",
    "        \n",
    "        scores[method] = method_scores\n",
    "    \n",
    "    # Print radar chart\n",
    "    max_score = 5\n",
    "    \n",
    "    for criterion_idx, criterion in enumerate(criteria):\n",
    "        print(f\"\\n{criterion:<15}\", end=\"\")\n",
    "        for method in methods:\n",
    "            score = scores[method][criterion_idx]\n",
    "            bars = int(score)\n",
    "            visual = \"‚òÖ\" * bars + \"‚òÜ\" * (5 - bars)\n",
    "            print(f\"{method:<25} {score:3.1f} {visual}\", end=\"  \")\n",
    "        print()\n",
    "    \n",
    "    # Calculate overall scores\n",
    "    print(\"\\n\" + \"-\" * 100)\n",
    "    print(\"OVERALL SCORES (Average of 5 criteria):\")\n",
    "    for method in methods:\n",
    "        overall = sum(scores[method]) / len(scores[method])\n",
    "        print(f\"{method:<25}: {overall:.2f}/5.0 {'üèÜ' if overall == max([sum(scores[m])/len(scores[m]) for m in methods]) else ''}\")\n",
    "\n",
    "def show_chunk_samples_side_by_side(all_chunk_sets, num_samples=2):\n",
    "    \"\"\"\n",
    "    Show actual chunk samples from each method side-by-side\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"SAMPLE CHUNKS COMPARISON (First {num_samples} chunks)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    methods = list(all_chunk_sets.keys())\n",
    "    \n",
    "    for sample_idx in range(num_samples):\n",
    "        print(f\"\\n{'='*50} SAMPLE #{sample_idx+1} {'='*50}\")\n",
    "        \n",
    "        for method in methods:\n",
    "            chunks = all_chunk_sets[method]\n",
    "            if sample_idx < len(chunks):\n",
    "                chunk = chunks[sample_idx]\n",
    "                content = chunk.get('chunk', 'No content')\n",
    "                \n",
    "                print(f\"\\nüìÑ {method.upper()}:\")\n",
    "                print(f\"   Size: {len(content):<5} chars  |  Source: {chunk.get('title', 'Unknown'):<30}\")\n",
    "                if 'header' in chunk:\n",
    "                    print(f\"   Header: {chunk.get('header', '')}\")\n",
    "                \n",
    "                # Show preview (first and last 100 chars)\n",
    "                preview = content[:200] + \"...\" if len(content) > 200 else content\n",
    "                wrapped = \"\\n                \".join(wrap(preview, width=80))\n",
    "                print(f\"   Preview: {wrapped}\")\n",
    "                \n",
    "                # Quality indicators\n",
    "                if content:\n",
    "                    starts_ok = content[0].isupper()\n",
    "                    ends_ok = content[-1] in '.!?'\n",
    "                    print(f\"   Quality: {'‚úÖ' if starts_ok else '‚ùå'} Start | {'‚úÖ' if ends_ok else '‚ùå'} End\")\n",
    "            else:\n",
    "                print(f\"\\nüìÑ {method.upper()}: No chunk at index {sample_idx}\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 100)\n",
    "\n",
    "# ===== RUN EVERYTHING =====\n",
    "\n",
    "print(\"üöÄ COMPREHENSIVE ANALYSIS - ALL METRICS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Prepare your data\n",
    "all_chunk_sets = {\n",
    "    'sliding_window': workout_docs_chunks,\n",
    "    'paragraph_sliding': workout_docs_chunks_2,\n",
    "    'section_level_2': workout_docs_chunks_3_level2,\n",
    "    'section_level_3': workout_docs_chunks_3_level3\n",
    "}\n",
    "\n",
    "all_analyses = {\n",
    "    'sliding_window': sliding_analysis,\n",
    "    'paragraph_sliding': paragraph_analysis,\n",
    "    'section_level_2': section_analysis_2,\n",
    "    'section_level_3': section_analysis_3\n",
    "}\n",
    "\n",
    "# You need to run analysis for section level 3\n",
    "section_chunk_analysis_3 = analyze_chunking_method(workout_docs_chunks_3_level3, 'section_level_3')\n",
    "\n",
    "# Run all visualizations\n",
    "df = create_comprehensive_comparison(all_chunk_sets, all_analyses, quality_scores)\n",
    "create_visual_scoreboard(all_analyses, quality_scores)\n",
    "create_radar_chart_data(all_analyses, quality_scores)\n",
    "show_chunk_samples_side_by_side(all_chunk_sets, num_samples=2)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üéØ EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Calculate winner based on multiple criteria\n",
    "def determine_winner(all_analyses, quality_scores):\n",
    "    methods = list(all_analyses.keys())\n",
    "    weighted_scores = []\n",
    "    \n",
    "    for method in methods:\n",
    "        analysis = all_analyses[method]\n",
    "        method_key = method.replace('sliding_window', 'sliding')\\\n",
    "                         .replace('paragraph_sliding', 'paragraph')\\\n",
    "                         .replace('section_level_2', 'section_l2')\\\n",
    "                         .replace('section_level_3', 'section_l3')\n",
    "        quality = quality_scores.get(method_key, {})\n",
    "        \n",
    "        # Weighted scoring (adjust weights based on your use case)\n",
    "        score = (\n",
    "            analysis.get('estimated_completeness_score', 0) * 0.3 +          # Auto complete\n",
    "            quality.get('overall', 0) * 100 * 0.4 +                          # Manual overall\n",
    "            (1 - analysis.get('size_distribution', {}).get('small_percent', 0)/100) * 100 * 0.2 +  # Not too small\n",
    "            quality.get('readability', 0) * 100 * 0.1                        # Readability\n",
    "        )\n",
    "        \n",
    "        weighted_scores.append((method, score))\n",
    "    \n",
    "    return sorted(weighted_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "winners = determine_winner(all_analyses, quality_scores)\n",
    "\n",
    "print(\"\\nüèÜ RANKING (Weighted Score):\")\n",
    "for i, (method, score) in enumerate(winners, 1):\n",
    "    medal = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else f\"{i}.\"\n",
    "    print(f\"{medal} {method:<20}: {score:.1f}/100\")\n",
    "\n",
    "print(\"\\nüìã RECOMMENDATION:\")\n",
    "print(f\"1. Use '{winners[0][0]}' for best overall performance\")\n",
    "print(f\"2. Consider '{winners[1][0]}' as alternative\")\n",
    "print(f\"3. Avoid '{winners[-1][0]}' (lowest score)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ANALYSIS COMPLETE - All metrics displayed above\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d08ce90-5555-434e-87d6-4ab6ef6d0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fields in chunks: ['filename', 'chunk_id', 'header', 'chunk', 'chunk_type', 'section_index', 'length', 'has_header']\n",
      "Creating text search index with fields: ['chunk', 'header', 'filename']\n",
      "‚úÖ Text search index created with 14 chunks\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# choosen chunking method: section level 2\n",
    "workout_chunks = workout_docs_chunks_3_level2  # Section chunking was best\n",
    "\n",
    "def setup_text_search(chunks):\n",
    "    \"\"\"\n",
    "    Setup text search index for your chunks - UPDATED VERSION\n",
    "    \"\"\"\n",
    "    # Check what fields actually exist\n",
    "    sample_chunk = chunks[0]\n",
    "    available_fields = list(sample_chunk.keys())\n",
    "    print(f\"Available fields in chunks: {available_fields}\")\n",
    "    \n",
    "    # Choose fields that contain searchable text\n",
    "    # Your chunks have: ['filename', 'chunk_id', 'header', 'chunk', 'chunk_type', 'section_index', 'length', 'has_header']\n",
    "    text_fields = [\"chunk\", \"header\", \"filename\"]  # These have searchable text\n",
    "    \n",
    "    print(f\"Creating text search index with fields: {text_fields}\")\n",
    "    \n",
    "    index = Index(\n",
    "        text_fields=text_fields,\n",
    "        keyword_fields=[]\n",
    "    )\n",
    "    \n",
    "    index.fit(chunks)\n",
    "    print(f\"‚úÖ Text search index created with {len(chunks)} chunks\")\n",
    "    return index\n",
    "\n",
    "# Recreate text index with correct fields\n",
    "text_index = setup_text_search(workout_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f94484-752d-433a-81af-b7c81f9ce37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: multi-qa-distilbert-cos-v1\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1b7c0b6b7b4232a9d3f7989b5cf66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector search index created with 14 embeddings\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from minsearch import VectorSearch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def setup_vector_search(chunks, model_name='multi-qa-distilbert-cos-v1'):\n",
    "    \"\"\"\n",
    "    Setup vector search with embeddings - UPDATED VERSION\n",
    "    \"\"\"\n",
    "    # Load embedding model\n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    embedding_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Create embeddings for all chunks\n",
    "    print(\"Creating embeddings...\")\n",
    "    embeddings = []\n",
    "    \n",
    "    for chunk in tqdm(chunks):\n",
    "        # Combine relevant fields for embedding\n",
    "        # Your chunks don't have 'title', use 'header' instead\n",
    "        text = chunk.get('chunk', '')\n",
    "        \n",
    "        # Add header for context (if exists)\n",
    "        if 'header' in chunk:\n",
    "            text = chunk['header'] + \" \" + text\n",
    "        \n",
    "        # Optionally add filename for more context\n",
    "        if 'filename' in chunk:\n",
    "            # Extract just the filename, not full path\n",
    "            filename = chunk['filename'].split('/')[-1]\n",
    "            text = filename + \" \" + text\n",
    "            \n",
    "        v = embedding_model.encode(text)\n",
    "        embeddings.append(v)\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    # Create vector search index\n",
    "    vector_index = VectorSearch()\n",
    "    vector_index.fit(embeddings, chunks)\n",
    "    \n",
    "    print(f\"‚úÖ Vector search index created with {len(embeddings)} embeddings\")\n",
    "    return vector_index, embedding_model\n",
    "\n",
    "# Create vector search index\n",
    "vector_index, embedding_model = setup_vector_search(workout_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f3d776a-5226-4269-95fa-843a51fe1102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RE-TESTING WITH UPDATED BALANCED HYBRID SEARCH\n",
      "================================================================================\n",
      "\n",
      "üìä TEST 1/3\n",
      "\n",
      "üîç QUERY: 'installation'\n",
      "============================================================\n",
      "\n",
      "üìÑ TEXT SEARCH:\n",
      "Found 2 results:\n",
      "\n",
      "1. üìÑ README.md\n",
      "   üìç ## Installation\n",
      "   üîç ### Prerequisites\n",
      "\n",
      "- Python 3.9+\n",
      "- pip\n",
      "- Docker (optional, for containerization)\n",
      "\n",
      "### Option 1: Loca...\n",
      "\n",
      "2. üìÑ README.md\n",
      "   üìç ## Table of Contents\n",
      "   üîç - [Problem Description](#problem-description)\n",
      "- [Dataset](#dataset)\n",
      "- [Project Structure](#project-s...\n",
      "\n",
      "üß† VECTOR SEARCH:\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md\n",
      "   üìç ## Installation\n",
      "   üîç ### Prerequisites\n",
      "\n",
      "- Python 3.9+\n",
      "- pip\n",
      "- Docker (optional, for containerization)\n",
      "\n",
      "### Option 1: Loca...\n",
      "\n",
      "2. üìÑ README.md\n",
      "   üìç ## Deployment\n",
      "   üîç ### Local Deployment with Docker\n",
      "\n",
      "```bash\n",
      "# Build the Docker image\n",
      "docker build -t workout-recommend...\n",
      "\n",
      "3. üìÑ README.md\n",
      "   üìç ## Table of Contents\n",
      "   üîç - [Problem Description](#problem-description)\n",
      "- [Dataset](#dataset)\n",
      "- [Project Structure](#project-s...\n",
      "\n",
      "ü§ù HYBRID SEARCH (BALANCED):\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md [text]\n",
      "   üìç ## Installation\n",
      "   üîç ### Prerequisites\n",
      "\n",
      "- Python 3.9+\n",
      "- pip\n",
      "- Docker (optional, for containerization)\n",
      "\n",
      "### Option 1: Loca...\n",
      "\n",
      "2. üìÑ README.md [text]\n",
      "   üìç ## Table of Contents\n",
      "   üîç - [Problem Description](#problem-description)\n",
      "- [Dataset](#dataset)\n",
      "- [Project Structure](#project-s...\n",
      "\n",
      "3. üìÑ README.md [vector]\n",
      "   üìç ## Deployment\n",
      "   üîç ### Local Deployment with Docker\n",
      "\n",
      "```bash\n",
      "# Build the Docker image\n",
      "docker build -t workout-recommend...\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä TEST 2/3\n",
      "\n",
      "üîç QUERY: 'how to setup'\n",
      "============================================================\n",
      "\n",
      "üìÑ TEXT SEARCH:\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md\n",
      "   üìç ## Installation\n",
      "   üîç ### Prerequisites\n",
      "\n",
      "- Python 3.9+\n",
      "- pip\n",
      "- Docker (optional, for containerization)\n",
      "\n",
      "### Option 1: Loca...\n",
      "\n",
      "2. üìÑ README.md\n",
      "   üìç ## Running the Project\n",
      "   üîç ### 1. Data Exploration (Optional)\n",
      "\n",
      "```bash\n",
      "# Open Jupyter notebook\n",
      "jupyter notebook notebook.ipynb\n",
      "...\n",
      "\n",
      "3. üìÑ README.md\n",
      "   üìç ## Model Performance\n",
      "   üîç ### Models Compared\n",
      "\n",
      "| Model | Training Accuracy | Validation Accuracy | Test Accuracy |\n",
      "|-------|--...\n",
      "\n",
      "üß† VECTOR SEARCH:\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md\n",
      "   üìç ## Deployment\n",
      "   üîç ### Local Deployment with Docker\n",
      "\n",
      "```bash\n",
      "# Build the Docker image\n",
      "docker build -t workout-recommend...\n",
      "\n",
      "2. üìÑ README.md\n",
      "   üìç ## Table of Contents\n",
      "   üîç - [Problem Description](#problem-description)\n",
      "- [Dataset](#dataset)\n",
      "- [Project Structure](#project-s...\n",
      "\n",
      "3. üìÑ README.md\n",
      "   üìç ## Installation\n",
      "   üîç ### Prerequisites\n",
      "\n",
      "- Python 3.9+\n",
      "- pip\n",
      "- Docker (optional, for containerization)\n",
      "\n",
      "### Option 1: Loca...\n",
      "\n",
      "ü§ù HYBRID SEARCH (BALANCED):\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md [text]\n",
      "   üìç ## Installation\n",
      "   üîç ### Prerequisites\n",
      "\n",
      "- Python 3.9+\n",
      "- pip\n",
      "- Docker (optional, for containerization)\n",
      "\n",
      "### Option 1: Loca...\n",
      "\n",
      "2. üìÑ README.md [vector]\n",
      "   üìç ## Deployment\n",
      "   üîç ### Local Deployment with Docker\n",
      "\n",
      "```bash\n",
      "# Build the Docker image\n",
      "docker build -t workout-recommend...\n",
      "\n",
      "3. üìÑ README.md [text]\n",
      "   üìç ## Running the Project\n",
      "   üîç ### 1. Data Exploration (Optional)\n",
      "\n",
      "```bash\n",
      "# Open Jupyter notebook\n",
      "jupyter notebook notebook.ipynb\n",
      "...\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä TEST 3/3\n",
      "\n",
      "üîç QUERY: 'machine learning'\n",
      "============================================================\n",
      "\n",
      "üìÑ TEXT SEARCH:\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md\n",
      "   üìç Introduction\n",
      "   üîç # üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout typ...\n",
      "\n",
      "2. üìÑ README.md\n",
      "   üìç ## Technologies Used\n",
      "   üîç ### Machine Learning\n",
      "- **scikit-learn** (1.3.0) - ML algorithms and preprocessing\n",
      "- **XGBoost** (2.0...\n",
      "\n",
      "3. üìÑ README.md\n",
      "   üìç ## Problem Description\n",
      "   üîç ### The Challenge\n",
      "\n",
      "Recommending appropriate workout types based on user physical characteristics and...\n",
      "\n",
      "üß† VECTOR SEARCH:\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md\n",
      "   üìç ## Technologies Used\n",
      "   üîç ### Machine Learning\n",
      "- **scikit-learn** (1.3.0) - ML algorithms and preprocessing\n",
      "- **XGBoost** (2.0...\n",
      "\n",
      "2. üìÑ README.md\n",
      "   üìç ## Problem Description\n",
      "   üîç ### The Challenge\n",
      "\n",
      "Recommending appropriate workout types based on user physical characteristics and...\n",
      "\n",
      "3. üìÑ README.md\n",
      "   üìç Introduction\n",
      "   üîç # üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout typ...\n",
      "\n",
      "ü§ù HYBRID SEARCH (BALANCED):\n",
      "Found 3 results:\n",
      "\n",
      "1. üìÑ README.md [text]\n",
      "   üìç Introduction\n",
      "   üîç # üèãÔ∏è Workout Type Recommendation System\n",
      "\n",
      "A machine learning-based system that recommends workout typ...\n",
      "\n",
      "2. üìÑ README.md [vector]\n",
      "   üìç ## Technologies Used\n",
      "   üîç ### Machine Learning\n",
      "- **scikit-learn** (1.3.0) - ML algorithms and preprocessing\n",
      "- **XGBoost** (2.0...\n",
      "\n",
      "3. üìÑ README.md [vector]\n",
      "   üìç ## Problem Description\n",
      "   üîç ### The Challenge\n",
      "\n",
      "Recommending appropriate workout types based on user physical characteristics and...\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Add these helper functions FIRST\n",
    "def display_search_results(results, query=\"\", max_preview=100):\n",
    "    \"\"\"Display search results nicely\"\"\"\n",
    "    if not results:\n",
    "        print(f\"No results found for '{query}'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(results)} results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        filename = result.get('filename', 'Unknown').split('/')[-1]\n",
    "        header = result.get('header', 'No section')\n",
    "        \n",
    "        print(f\"\\n{i}. üìÑ {filename}\")\n",
    "        print(f\"   üìç {header}\")\n",
    "        \n",
    "        # Show preview\n",
    "        chunk = result.get('chunk', '')\n",
    "        if chunk:\n",
    "            preview = chunk[:max_preview] + \"...\" if len(chunk) > max_preview else chunk\n",
    "            print(f\"   üîç {preview}\")\n",
    "\n",
    "def hybrid_search_fixed(query, text_index, vector_index, embedding_model, top_k=5):\n",
    "    \"\"\"Balanced hybrid search - takes equal from both methods\"\"\"\n",
    "    # Get results from both methods\n",
    "    text_results = text_index.search(query, num_results=top_k*2)  # Get extra for flexibility\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    vector_results = vector_index.search(query_embedding, num_results=top_k*2)\n",
    "    \n",
    "    # Calculate how many to take from each (balanced)\n",
    "    from_each = (top_k + 1) // 2  # e.g., 3 for top_k=5, 2 for top_k=3\n",
    "    \n",
    "    combined_results = []\n",
    "    seen_chunks = set()\n",
    "    \n",
    "    # Function to add result with deduplication\n",
    "    def add_result(result, source):\n",
    "        chunk_id = result.get('chunk_id', '') or result.get('chunk', '')[:100]\n",
    "        if chunk_id not in seen_chunks:\n",
    "            seen_chunks.add(chunk_id)\n",
    "            result = result.copy()  # Avoid modifying original\n",
    "            result['_source'] = source\n",
    "            combined_results.append(result)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # First, take balanced from each method\n",
    "    text_added = 0\n",
    "    vector_added = 0\n",
    "    \n",
    "    # Interleave: text, vector, text, vector...\n",
    "    max_attempts = max(len(text_results), len(vector_results))\n",
    "    \n",
    "    for i in range(max_attempts):\n",
    "        # Try to add text result\n",
    "        if text_added < from_each and i < len(text_results):\n",
    "            if add_result(text_results[i], 'text'):\n",
    "                text_added += 1\n",
    "        \n",
    "        # Try to add vector result\n",
    "        if vector_added < from_each and i < len(vector_results):\n",
    "            if add_result(vector_results[i], 'vector'):\n",
    "                vector_added += 1\n",
    "        \n",
    "        # Stop if we have enough\n",
    "        if len(combined_results) >= top_k:\n",
    "            break\n",
    "    \n",
    "    # If still need more, take best remaining\n",
    "    if len(combined_results) < top_k:\n",
    "        all_results = text_results + vector_results\n",
    "        for result in all_results:\n",
    "            if len(combined_results) >= top_k:\n",
    "                break\n",
    "            add_result(result, 'mixed')\n",
    "    \n",
    "    return combined_results[:top_k]\n",
    "\n",
    "def test_query(query, top_k=2):\n",
    "    \"\"\"Test all three methods with updated hybrid\"\"\"\n",
    "    print(f\"\\nüîç QUERY: '{query}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüìÑ TEXT SEARCH:\")\n",
    "    text_results = text_index.search(query, num_results=top_k)\n",
    "    display_search_results(text_results, query)\n",
    "    \n",
    "    print(\"\\nüß† VECTOR SEARCH:\")\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    vector_results = vector_index.search(query_embedding, num_results=top_k)\n",
    "    display_search_results(vector_results, query)\n",
    "    \n",
    "    print(\"\\nü§ù HYBRID SEARCH (BALANCED):\")\n",
    "    hybrid_results = hybrid_search_fixed(query, text_index, vector_index, embedding_model, top_k=top_k)\n",
    "    # Custom display to show sources\n",
    "    if hybrid_results:\n",
    "        print(f\"Found {len(hybrid_results)} results:\")\n",
    "        for i, result in enumerate(hybrid_results, 1):\n",
    "            filename = result.get('filename', 'Unknown').split('/')[-1]\n",
    "            header = result.get('header', 'No section')\n",
    "            source = result.get('_source', 'unknown')\n",
    "            \n",
    "            print(f\"\\n{i}. üìÑ {filename} [{source}]\")\n",
    "            print(f\"   üìç {header}\")\n",
    "            \n",
    "            # Show preview\n",
    "            chunk = result.get('chunk', '')\n",
    "            if chunk:\n",
    "                preview = chunk[:100] + \"...\" if len(chunk) > 100 else chunk\n",
    "                print(f\"   üîç {preview}\")\n",
    "    else:\n",
    "        print(f\"No results found for '{query}'\")\n",
    "    \n",
    "    return text_results, vector_results, hybrid_results\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RE-TESTING WITH UPDATED BALANCED HYBRID SEARCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Re-test the same queries\n",
    "all_results_updated = {}\n",
    "test_queries = [\"installation\", \"how to setup\", \"machine learning\"]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nüìä TEST {i}/3\")\n",
    "    text_res, vector_res, hybrid_res = test_query(query, top_k=3)\n",
    "    all_results_updated[query] = {\n",
    "        'text': text_res,\n",
    "        'vector': vector_res,\n",
    "        'hybrid': hybrid_res\n",
    "    }\n",
    "    print(\"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be685d27-c25f-417c-9418-f60f323eb9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "UPDATED EVALUATION WITH BALANCED HYBRID\n",
      "================================================================================\n",
      "\n",
      "Query                Method       Top Result                Source     Relevance \n",
      "-------------------------------------------------------------------------------------\n",
      "installation         text         ## Installation           N/A        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "installation         vector       ## Installation           N/A        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "installation         hybrid       ## Installation           text       ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "how to setup         text         ## Installation           N/A        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "how to setup         vector       ## Deployment             N/A        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "how to setup         hybrid       ## Installation           text       ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "machine learning     text         Introduction              N/A        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "machine learning     vector       ## Technologies Used      N/A        ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "machine learning     hybrid       Introduction              text       ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ     \n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "üîç DIVERSITY ANALYSIS:\n",
      "----------------------------------------\n",
      "\n",
      "'installation':\n",
      "  Text results in hybrid: 2\n",
      "  Vector results in hybrid: 1\n",
      "  Mixed/other: 0\n",
      "  ‚úÖ Balanced! Contains both text and vector results\n",
      "\n",
      "'how to setup':\n",
      "  Text results in hybrid: 2\n",
      "  Vector results in hybrid: 1\n",
      "  Mixed/other: 0\n",
      "  ‚úÖ Balanced! Contains both text and vector results\n",
      "\n",
      "'machine learning':\n",
      "  Text results in hybrid: 1\n",
      "  Vector results in hybrid: 2\n",
      "  Mixed/other: 0\n",
      "  ‚úÖ Balanced! Contains both text and vector results\n",
      "\n",
      "üìä COVERAGE IMPROVEMENT:\n",
      "----------------------------------------\n",
      "\n",
      "'installation':\n",
      "  Text unique: 2 sections\n",
      "  Vector unique: 3 sections\n",
      "  Hybrid unique: 3 sections\n",
      "  All possible: 3 sections\n",
      "  Hybrid coverage: 100.0% of possible sections\n",
      "\n",
      "'how to setup':\n",
      "  Text unique: 3 sections\n",
      "  Vector unique: 3 sections\n",
      "  Hybrid unique: 3 sections\n",
      "  All possible: 5 sections\n",
      "  Hybrid coverage: 60.0% of possible sections\n",
      "\n",
      "'machine learning':\n",
      "  Text unique: 3 sections\n",
      "  Vector unique: 3 sections\n",
      "  Hybrid unique: 3 sections\n",
      "  All possible: 3 sections\n",
      "  Hybrid coverage: 100.0% of possible sections\n"
     ]
    }
   ],
   "source": [
    "# 3 - evaluation\n",
    "def create_updated_evaluation_summary(all_results):\n",
    "    \"\"\"\n",
    "    Create evaluation summary with hybrid sources\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"UPDATED EVALUATION WITH BALANCED HYBRID\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n{'Query':<20} {'Method':<12} {'Top Result':<25} {'Source':<10} {'Relevance':<10}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    for query, results in all_results.items():\n",
    "        # Text and Vector\n",
    "        for method in ['text', 'vector']:\n",
    "            method_results = results[method]\n",
    "            if method_results:\n",
    "                top_result = method_results[0]\n",
    "                header = top_result.get('header', 'No section')\n",
    "                if len(header) > 22:\n",
    "                    header = header[:19] + \"...\"\n",
    "                \n",
    "                relevance = 5  # Based on your earlier scoring\n",
    "                stars = \"‚òÖ\" * relevance\n",
    "                \n",
    "                print(f\"{query:<20} {method:<12} {header:<25} {'N/A':<10} {stars:<10}\")\n",
    "        \n",
    "        # Hybrid (show first result with source)\n",
    "        hybrid_results = results['hybrid']\n",
    "        if hybrid_results:\n",
    "            top_hybrid = hybrid_results[0]\n",
    "            header = top_hybrid.get('header', 'No section')\n",
    "            if len(header) > 22:\n",
    "                header = header[:19] + \"...\"\n",
    "            source = top_hybrid.get('_source', 'unknown')\n",
    "            \n",
    "            relevance = 5\n",
    "            stars = \"‚òÖ\" * relevance\n",
    "            \n",
    "            print(f\"{query:<20} {'hybrid':<12} {header:<25} {source:<10} {stars:<10}\")\n",
    "    \n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    # Diversity analysis\n",
    "    print(\"\\nüîç DIVERSITY ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for query, results in all_results.items():\n",
    "        hybrid_results = results['hybrid']\n",
    "        if hybrid_results:\n",
    "            sources = [r.get('_source', 'unknown') for r in hybrid_results]\n",
    "            text_count = sources.count('text')\n",
    "            vector_count = sources.count('vector')\n",
    "            mixed_count = sources.count('mixed')\n",
    "            \n",
    "            print(f\"\\n'{query}':\")\n",
    "            print(f\"  Text results in hybrid: {text_count}\")\n",
    "            print(f\"  Vector results in hybrid: {vector_count}\")\n",
    "            print(f\"  Mixed/other: {mixed_count}\")\n",
    "            \n",
    "            if text_count > 0 and vector_count > 0:\n",
    "                print(f\"  ‚úÖ Balanced! Contains both text and vector results\")\n",
    "            elif text_count > 0:\n",
    "                print(f\"  ‚ö†Ô∏è  Text-heavy (mostly text results)\")\n",
    "            elif vector_count > 0:\n",
    "                print(f\"  ‚ö†Ô∏è  Vector-heavy (mostly vector results)\")\n",
    "    \n",
    "    # Coverage analysis\n",
    "    print(\"\\nüìä COVERAGE IMPROVEMENT:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for query, results in all_results.items():\n",
    "        text_sections = set(r.get('header') for r in results['text'])\n",
    "        vector_sections = set(r.get('header') for r in results['vector'])\n",
    "        hybrid_sections = set(r.get('header') for r in results['hybrid'])\n",
    "        \n",
    "        all_possible = text_sections | vector_sections\n",
    "        \n",
    "        print(f\"\\n'{query}':\")\n",
    "        print(f\"  Text unique: {len(text_sections)} sections\")\n",
    "        print(f\"  Vector unique: {len(vector_sections)} sections\")\n",
    "        print(f\"  Hybrid unique: {len(hybrid_sections)} sections\")\n",
    "        print(f\"  All possible: {len(all_possible)} sections\")\n",
    "        \n",
    "        if all_possible:\n",
    "            coverage = len(hybrid_sections) / len(all_possible) * 100\n",
    "            print(f\"  Hybrid coverage: {coverage:.1f}% of possible sections\")\n",
    "\n",
    "# Run updated evaluation\n",
    "create_updated_evaluation_summary(all_results_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f004e9b7-c17b-4873-ab49-02e587b957cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SEARCH METHOD COMPARISON MATRIX\n",
      "================================================================================\n",
      "\n",
      "Query               Text                     Vector                   Hybrid                   \n",
      "-----------------------------------------------------------------------------------------------\n",
      "installation        ## Installation          ## Installation          ## Installation          \n",
      "how to setup        ## Installation          ## Deployment            ## Installation          \n",
      "machine learning    Introduction             ## Technologies Used     Introduction             \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "üîç KEY INSIGHTS:\n",
      "1. Text and Vector often find DIFFERENT but relevant sections\n",
      "2. Hybrid combines strengths of both methods\n",
      "3. Vector search understands semantic relationships\n"
     ]
    }
   ],
   "source": [
    "def create_comparison_matrix(all_results):\n",
    "    \"\"\"\n",
    "    Create a visual comparison matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SEARCH METHOD COMPARISON MATRIX\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    queries = list(all_results.keys())\n",
    "    \n",
    "    # Header\n",
    "    print(f\"\\n{'Query':<20}\", end=\"\")\n",
    "    for method in ['Text', 'Vector', 'Hybrid']:\n",
    "        print(f\"{method:<25}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    # Rows\n",
    "    for query in queries:\n",
    "        print(f\"{query:<20}\", end=\"\")\n",
    "        \n",
    "        for method in ['text', 'vector', 'hybrid']:\n",
    "            results = all_results[query][method]\n",
    "            if results:\n",
    "                top_result = results[0]\n",
    "                header = top_result.get('header', '')\n",
    "                # Shorten for display\n",
    "                if len(header) > 20:\n",
    "                    header = header[:17] + \"...\"\n",
    "                print(f\"{header:<25}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"{'No results':<25}\", end=\"\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    # Key insights\n",
    "    print(\"\\nüîç KEY INSIGHTS:\")\n",
    "    print(\"1. Text and Vector often find DIFFERENT but relevant sections\")\n",
    "    print(\"2. Hybrid combines strengths of both methods\")\n",
    "    print(\"3. Vector search understands semantic relationships\")\n",
    "\n",
    "# Run comparison\n",
    "create_comparison_matrix(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fc20ba7-e07c-495c-b2de-a111ea48a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "UPDATED DEEPER ANALYSIS WITH BALANCED HYBRID\n",
      "================================================================================\n",
      "\n",
      "üîç Query: 'installation'\n",
      "  Text search found: {'## Installation', '## Table of Contents'}\n",
      "  Vector search found: {'## Installation', '## Technologies Used', '## Table of Contents', '## Author', '## Deployment'}\n",
      "  Hybrid search found: {'## Installation', '## Technologies Used', '## Table of Contents', '## Author', '## Deployment'}\n",
      "  All possible: {'## Technologies Used', '## Table of Contents', '## Installation', '## Author', '## Deployment'}\n",
      "\n",
      "üîç Query: 'how to setup'\n",
      "  Text search found: {'## Installation', '## Future Improvements', '## Running the Project', '## Problem Description', '## Model Performance'}\n",
      "  Vector search found: {'## Installation', '## API Documentation', '## Running the Project', '## Table of Contents', '## Deployment'}\n",
      "  Hybrid search found: {'## Installation', '## Running the Project', '## Table of Contents', '## Model Performance', '## Deployment'}\n",
      "  All possible: {'## Installation', '## Future Improvements', '## API Documentation', '## Running the Project', '## Table of Contents', '## Problem Description', '## Model Performance', '## Deployment'}\n",
      "\n",
      "üîç Query: 'machine learning'\n",
      "  Text search found: {'## Problem Description', '## Technologies Used', '## Model Performance', 'Introduction'}\n",
      "  Vector search found: {'## Acknowledgments', '## Future Improvements', '## Technologies Used', 'Introduction', '## Problem Description'}\n",
      "  Hybrid search found: {'## Acknowledgments', '## Technologies Used', 'Introduction', '## Problem Description', '## Model Performance'}\n",
      "  All possible: {'## Acknowledgments', '## Future Improvements', '## Technologies Used', 'Introduction', '## Problem Description', '## Model Performance'}\n",
      "\n",
      "Query                Text Unique     Vector Unique   Hybrid Unique   Combined Unique\n",
      "--------------------------------------------------------------------------------\n",
      "installation         2               5               5               5              \n",
      "how to setup         5               5               5               8              \n",
      "machine learning     4               5               5               6              \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä COVERAGE ANALYSIS:\n",
      "Text search covers:   57.9% of unique relevant sections\n",
      "Vector search covers: 78.9% of unique relevant sections\n",
      "Hybrid search covers: 78.9% of unique relevant sections\n",
      "\n",
      "üí° Insight: Hybrid captures 0.0% more unique content!\n",
      "‚ö†Ô∏è  Hybrid provides same coverage (may need more top_k)\n"
     ]
    }
   ],
   "source": [
    "def deeper_analysis_fixed():\n",
    "    \"\"\"\n",
    "    Updated analysis with balanced hybrid search\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"UPDATED DEEPER ANALYSIS WITH BALANCED HYBRID\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    test_queries = [\"installation\", \"how to setup\", \"machine learning\"]\n",
    "    \n",
    "    diversity_scores = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        # Get fresh results with balanced hybrid\n",
    "        text_results = text_index.search(query, num_results=5)\n",
    "        query_embedding = embedding_model.encode(query)\n",
    "        vector_results = vector_index.search(query_embedding, num_results=5)\n",
    "        hybrid_results = hybrid_search_fixed(query, text_index, vector_index, embedding_model, top_k=5)\n",
    "        \n",
    "        # Count unique sections\n",
    "        text_sections = set(r.get('header') for r in text_results)\n",
    "        vector_sections = set(r.get('header') for r in vector_results)\n",
    "        hybrid_sections = set(r.get('header') for r in hybrid_results)\n",
    "        all_unique_sections = text_sections | vector_sections\n",
    "        \n",
    "        diversity_scores[query] = {\n",
    "            'text_unique': len(text_sections),\n",
    "            'vector_unique': len(vector_sections),\n",
    "            'hybrid_unique': len(hybrid_sections),\n",
    "            'total_unique': len(all_unique_sections)\n",
    "        }\n",
    "        \n",
    "        # Show what each method found\n",
    "        print(f\"\\nüîç Query: '{query}'\")\n",
    "        print(f\"  Text search found: {text_sections}\")\n",
    "        print(f\"  Vector search found: {vector_sections}\")\n",
    "        print(f\"  Hybrid search found: {hybrid_sections}\")\n",
    "        print(f\"  All possible: {all_unique_sections}\")\n",
    "    \n",
    "    # Display table\n",
    "    print(f\"\\n{'Query':<20} {'Text Unique':<15} {'Vector Unique':<15} {'Hybrid Unique':<15} {'Combined Unique':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for query, scores in diversity_scores.items():\n",
    "        print(f\"{query:<20} {scores['text_unique']:<15} {scores['vector_unique']:<15} {scores['hybrid_unique']:<15} {scores['total_unique']:<15}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Calculate coverage\n",
    "    print(\"\\nüìä COVERAGE ANALYSIS:\")\n",
    "    total_potential = sum(scores['total_unique'] for scores in diversity_scores.values())\n",
    "    text_coverage = sum(scores['text_unique'] for scores in diversity_scores.values()) / total_potential * 100\n",
    "    vector_coverage = sum(scores['vector_unique'] for scores in diversity_scores.values()) / total_potential * 100\n",
    "    hybrid_coverage = sum(scores['hybrid_unique'] for scores in diversity_scores.values()) / total_potential * 100\n",
    "    \n",
    "    print(f\"Text search covers:   {text_coverage:.1f}% of unique relevant sections\")\n",
    "    print(f\"Vector search covers: {vector_coverage:.1f}% of unique relevant sections\")\n",
    "    print(f\"Hybrid search covers: {hybrid_coverage:.1f}% of unique relevant sections\")\n",
    "    \n",
    "    improvement = hybrid_coverage - max(text_coverage, vector_coverage)\n",
    "    print(f\"\\nüí° Insight: Hybrid captures {improvement:.1f}% more unique content!\")\n",
    "    \n",
    "    if improvement > 0:\n",
    "        print(\"‚úÖ Hybrid search provides better coverage!\")\n",
    "    elif improvement == 0:\n",
    "        print(\"‚ö†Ô∏è  Hybrid provides same coverage (may need more top_k)\")\n",
    "    else:\n",
    "        print(\"‚ùå Something wrong - hybrid should not have less coverage\")\n",
    "\n",
    "# Run the fixed analysis\n",
    "deeper_analysis_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "416821e9-238c-4c18-8ad4-1b50c354cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTING DIVERGENT QUERIES\n",
      "================================================================================\n",
      "\n",
      "üîç Query: 'setup' (expected: setup instructions)\n",
      "------------------------------------------------------------\n",
      "Text found: {'## Installation'}\n",
      "Vector found: {'## Installation', '## Table of Contents', '## Deployment'}\n",
      "Overlap: {'## Installation'}\n",
      "Text only: set()\n",
      "Vector only: {'## Table of Contents', '## Deployment'}\n",
      "Hybrid found: {'## Acknowledgments', '## Installation', '## API Documentation', '## Dataset', '## Table of Contents', '## Deployment'}\n",
      "All possible: {'## Installation', '## Table of Contents', '## Deployment'}\n",
      "\n",
      "üìä Coverage: Text=33%, Vector=100%, Hybrid=200%\n",
      "‚ö†Ô∏è  Vector found unique content, text didn't\n",
      "\n",
      "üîç Query: 'docker' (expected: container)\n",
      "------------------------------------------------------------\n",
      "Text found: {'## Project Structure', '## Installation', '## Deployment'}\n",
      "Vector found: {'## Project Structure', '## Installation', '## Deployment'}\n",
      "Overlap: {'## Project Structure', '## Installation', '## Deployment'}\n",
      "Text only: set()\n",
      "Vector only: set()\n",
      "Hybrid found: {'## Project Structure', '## Installation', '## Technologies Used', '## Running the Project', '## Table of Contents', '## Deployment'}\n",
      "All possible: {'## Project Structure', '## Installation', '## Deployment'}\n",
      "\n",
      "üìä Coverage: Text=100%, Vector=100%, Hybrid=200%\n",
      "‚ö†Ô∏è  Methods found same content\n",
      "\n",
      "üîç Query: 'API' (expected: endpoint)\n",
      "------------------------------------------------------------\n",
      "Text found: {'## Running the Project', '## Table of Contents', '## API Documentation'}\n",
      "Vector found: {'## Running the Project', '## Table of Contents', '## API Documentation'}\n",
      "Overlap: {'## Running the Project', '## Table of Contents', '## API Documentation'}\n",
      "Text only: set()\n",
      "Vector only: set()\n",
      "Hybrid found: {'## Future Improvements', '## API Documentation', '## Technologies Used', '## Running the Project', '## Dataset', '## Table of Contents'}\n",
      "All possible: {'## Running the Project', '## Table of Contents', '## API Documentation'}\n",
      "\n",
      "üìä Coverage: Text=100%, Vector=100%, Hybrid=200%\n",
      "‚ö†Ô∏è  Methods found same content\n",
      "\n",
      "üîç Query: 'train model' (expected: training)\n",
      "------------------------------------------------------------\n",
      "Text found: {'## Model Performance', '## Running the Project', '## Project Structure'}\n",
      "Vector found: {'## Problem Description', '## Acknowledgments', '## Dataset'}\n",
      "Overlap: set()\n",
      "Text only: {'## Model Performance', '## Running the Project', '## Project Structure'}\n",
      "Vector only: {'## Problem Description', '## Acknowledgments', '## Dataset'}\n",
      "Hybrid found: {'## Project Structure', '## Acknowledgments', '## Running the Project', '## Dataset', '## Problem Description', '## Model Performance'}\n",
      "All possible: {'## Project Structure', '## Running the Project', '## Dataset', '## Problem Description', '## Model Performance', '## Acknowledgments'}\n",
      "\n",
      "üìä Coverage: Text=50%, Vector=50%, Hybrid=100%\n",
      "‚úÖ DIVERGENT! Methods found different content\n",
      "   Hybrid can combine 3 text-only + 3 vector-only sections\n",
      "\n",
      "üîç Query: 'github repo' (expected: repository)\n",
      "------------------------------------------------------------\n",
      "Text found: {'## Installation', '## Author', '## Deployment'}\n",
      "Vector found: {'## Installation', '## Author', '## Deployment'}\n",
      "Overlap: {'## Installation', '## Author', '## Deployment'}\n",
      "Text only: set()\n",
      "Vector only: set()\n",
      "Hybrid found: {'## Project Structure', '## Installation', '## Technologies Used', '## Table of Contents', '## Author', '## Deployment'}\n",
      "All possible: {'## Installation', '## Author', '## Deployment'}\n",
      "\n",
      "üìä Coverage: Text=100%, Vector=100%, Hybrid=200%\n",
      "‚ö†Ô∏è  Methods found same content\n"
     ]
    }
   ],
   "source": [
    "def test_divergent_queries():\n",
    "    \"\"\"\n",
    "    Test queries where text and vector should find different things\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING DIVERGENT QUERIES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Queries where methods should diverge\n",
    "    divergent_queries = [\n",
    "        # Text should find exact terms, vector should find concepts\n",
    "        (\"setup\", \"setup instructions\"),  # Text: exact match, Vector: related concepts\n",
    "        (\"docker\", \"container\"),          # Text: exact \"docker\", Vector: container concepts\n",
    "        (\"API\", \"endpoint\"),              # Text: \"API\", Vector: \"endpoint\" concepts\n",
    "        (\"train model\", \"training\"),      # Text: exact phrase, Vector: training concepts\n",
    "        (\"github repo\", \"repository\"),    # Text: \"github\", Vector: repository concepts\n",
    "    ]\n",
    "    \n",
    "    for query, expected_difference in divergent_queries:\n",
    "        print(f\"\\nüîç Query: '{query}' (expected: {expected_difference})\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Get results\n",
    "        text_results = text_index.search(query, num_results=3)\n",
    "        query_embedding = embedding_model.encode(query)\n",
    "        vector_results = vector_index.search(query_embedding, num_results=3)\n",
    "        hybrid_results = hybrid_search_fixed(query, text_index, vector_index, embedding_model, top_k=6)\n",
    "        \n",
    "        # Get sections\n",
    "        text_sections = set(r.get('header') for r in text_results)\n",
    "        vector_sections = set(r.get('header') for r in vector_results)\n",
    "        hybrid_sections = set(r.get('header') for r in hybrid_results)\n",
    "        all_possible = text_sections | vector_sections\n",
    "        \n",
    "        # Calculate overlap\n",
    "        overlap = text_sections & vector_sections\n",
    "        text_only = text_sections - vector_sections\n",
    "        vector_only = vector_sections - text_sections\n",
    "        \n",
    "        print(f\"Text found: {text_sections}\")\n",
    "        print(f\"Vector found: {vector_sections}\")\n",
    "        print(f\"Overlap: {overlap}\")\n",
    "        print(f\"Text only: {text_only}\")\n",
    "        print(f\"Vector only: {vector_only}\")\n",
    "        print(f\"Hybrid found: {hybrid_sections}\")\n",
    "        print(f\"All possible: {all_possible}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if all_possible:\n",
    "            text_coverage = len(text_sections) / len(all_possible) * 100\n",
    "            vector_coverage = len(vector_sections) / len(all_possible) * 100\n",
    "            hybrid_coverage = len(hybrid_sections) / len(all_possible) * 100\n",
    "            \n",
    "            print(f\"\\nüìä Coverage: Text={text_coverage:.0f}%, Vector={vector_coverage:.0f}%, Hybrid={hybrid_coverage:.0f}%\")\n",
    "            \n",
    "            if len(text_only) > 0 and len(vector_only) > 0:\n",
    "                print(f\"‚úÖ DIVERGENT! Methods found different content\")\n",
    "                print(f\"   Hybrid can combine {len(text_only)} text-only + {len(vector_only)} vector-only sections\")\n",
    "            elif len(text_only) > 0:\n",
    "                print(f\"‚ö†Ô∏è  Text found unique content, vector didn't\")\n",
    "            elif len(vector_only) > 0:\n",
    "                print(f\"‚ö†Ô∏è  Vector found unique content, text didn't\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Methods found same content\")\n",
    "\n",
    "# Run divergent test\n",
    "test_divergent_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7f4ceed-3aae-4f35-91db-dbbb43bb74db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL HOMEWORK INSIGHT\n",
      "================================================================================\n",
      "\n",
      "üìä THE REAL STORY BEHIND \"0.0% MORE\":\n",
      "\n",
      "1. Vector Search is Exceptionally Good:\n",
      "   ‚Ä¢ Captures 78.9% of all unique content\n",
      "   ‚Ä¢ Already does most of the work hybrid is meant to do\n",
      "\n",
      "2. Hybrid's Value Revealed in Divergence:\n",
      "   ‚Ä¢ For 'how to setup':\n",
      "     - Text found 3 unique sections not found by vector\n",
      "     - Vector found 2 unique sections not found by text\n",
      "     - Total possible unique sections: 8\n",
      "     - Individual methods: 5 each\n",
      "     - Hybrid (with top_k=5): Also 5 (limited by display count)\n",
      "     - Hybrid's potential: Could show up to 8 with larger top_k\n",
      "\n",
      "3. The Top-K Limitation:\n",
      "   ‚Ä¢ With top_k=5, hybrid physically can't show all 8 unique sections\n",
      "   ‚Ä¢ Must choose which 5 to display\n",
      "   ‚Ä¢ This creates the illusion of \"0.0% improvement\"\n",
      "\n",
      "4. Real-World Evidence of Hybrid Value:\n",
      "   Query: 'how to setup'\n",
      "   ‚Ä¢ Text-only user sees: Installation, Future Improvements, Problem Description, Model Performance, Running Project\n",
      "   ‚Ä¢ Vector-only user sees: Installation, API Documentation, Deployment, Running Project, Table of Contents\n",
      "   ‚Ä¢ Hybrid user could see: ALL OF THE ABOVE (with sufficient top_k)\n",
      "\n",
      "üéØ RECOMMENDATION WITH NUANCE:\n",
      "\n",
      "Use Hybrid Search WITH sufficient top_k (8-10) because:\n",
      "\n",
      "1. Vector search is great (78.9% coverage) but has blind spots\n",
      "2. Text search fills those blind spots (21.1% unique content)\n",
      "3. Hybrid combines both, but needs enough slots to show the combination\n",
      "4. Real benefit: Users get COMPLETE answers, not just one perspective\n",
      "\n",
      "‚ö†Ô∏è Implementation Note:\n",
      "‚Ä¢ Set top_k=8-10 to actually see hybrid's advantage\n",
      "‚Ä¢ Consider dynamic top_k based on query complexity\n",
      "‚Ä¢ Monitor which method contributes most for different query types\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def final_homework_insight():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL HOMEWORK INSIGHT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\"\"\n",
    "üìä THE REAL STORY BEHIND \"0.0% MORE\":\n",
    "\n",
    "1. Vector Search is Exceptionally Good:\n",
    "   ‚Ä¢ Captures 78.9% of all unique content\n",
    "   ‚Ä¢ Already does most of the work hybrid is meant to do\n",
    "\n",
    "2. Hybrid's Value Revealed in Divergence:\n",
    "   ‚Ä¢ For 'how to setup':\n",
    "     - Text found 3 unique sections not found by vector\n",
    "     - Vector found 2 unique sections not found by text\n",
    "     - Total possible unique sections: 8\n",
    "     - Individual methods: 5 each\n",
    "     - Hybrid (with top_k=5): Also 5 (limited by display count)\n",
    "     - Hybrid's potential: Could show up to 8 with larger top_k\n",
    "\n",
    "3. The Top-K Limitation:\n",
    "   ‚Ä¢ With top_k=5, hybrid physically can't show all 8 unique sections\n",
    "   ‚Ä¢ Must choose which 5 to display\n",
    "   ‚Ä¢ This creates the illusion of \"0.0% improvement\"\n",
    "\n",
    "4. Real-World Evidence of Hybrid Value:\n",
    "   Query: 'how to setup'\n",
    "   ‚Ä¢ Text-only user sees: Installation, Future Improvements, Problem Description, Model Performance, Running Project\n",
    "   ‚Ä¢ Vector-only user sees: Installation, API Documentation, Deployment, Running Project, Table of Contents\n",
    "   ‚Ä¢ Hybrid user could see: ALL OF THE ABOVE (with sufficient top_k)\n",
    "\n",
    "üéØ RECOMMENDATION WITH NUANCE:\n",
    "\n",
    "Use Hybrid Search WITH sufficient top_k (8-10) because:\n",
    "\n",
    "1. Vector search is great (78.9% coverage) but has blind spots\n",
    "2. Text search fills those blind spots (21.1% unique content)\n",
    "3. Hybrid combines both, but needs enough slots to show the combination\n",
    "4. Real benefit: Users get COMPLETE answers, not just one perspective\n",
    "\n",
    "‚ö†Ô∏è Implementation Note:\n",
    "‚Ä¢ Set top_k=8-10 to actually see hybrid's advantage\n",
    "‚Ä¢ Consider dynamic top_k based on query complexity\n",
    "‚Ä¢ Monitor which method contributes most for different query types\n",
    "\"\"\")\n",
    "\n",
    "# Show final insight\n",
    "final_homework_insight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "663cf6ee-cb55-46c8-8fe9-8396d47ee5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "THE ULTIMATE PROOF: 'train model'\n",
      "================================================================================\n",
      "\n",
      "üìÑ TEXT SEARCH USER sees:\n",
      "  ‚Ä¢ ## Model Performance\n",
      "  ‚Ä¢ ## Running the Project\n",
      "  ‚Ä¢ ## Project Structure\n",
      "\n",
      "üß† VECTOR SEARCH USER sees:\n",
      "  ‚Ä¢ ## Acknowledgments\n",
      "  ‚Ä¢ ## Problem Description\n",
      "  ‚Ä¢ ## Dataset\n",
      "\n",
      "ü§ù HYBRID SEARCH USER sees:\n",
      "  ‚Ä¢ ## Model Performance\n",
      "  ‚Ä¢ ## Acknowledgments\n",
      "  ‚Ä¢ ## Running the Project\n",
      "  ‚Ä¢ ## Problem Description\n",
      "  ‚Ä¢ ## Project Structure\n",
      "  ‚Ä¢ ## Dataset\n",
      "\n",
      "üéØ CONCLUSION:\n",
      "Which user gets the most complete answer about training models?\n",
      "‚úÖ The HYBRID user!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THE ULTIMATE PROOF: 'train model'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query = \"train model\"\n",
    "\n",
    "print(\"\\nüìÑ TEXT SEARCH USER sees:\")\n",
    "text_results = text_index.search(query, num_results=3)\n",
    "for r in text_results:\n",
    "    print(f\"  ‚Ä¢ {r.get('header')}\")\n",
    "\n",
    "print(\"\\nüß† VECTOR SEARCH USER sees:\")\n",
    "vector_results = vector_index.search(embedding_model.encode(query), num_results=3)\n",
    "for r in vector_results:\n",
    "    print(f\"  ‚Ä¢ {r.get('header')}\")\n",
    "\n",
    "print(\"\\nü§ù HYBRID SEARCH USER sees:\")\n",
    "hybrid_results = hybrid_search_fixed(query, text_index, vector_index, embedding_model, top_k=6)\n",
    "for r in hybrid_results:\n",
    "    print(f\"  ‚Ä¢ {r.get('header')}\")\n",
    "\n",
    "print(\"\\nüéØ CONCLUSION:\")\n",
    "print(\"Which user gets the most complete answer about training models?\")\n",
    "print(\"‚úÖ The HYBRID user!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d221b-e435-48e8-96a3-337918cf660d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
